{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e6d5b50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T02:43:24.078835Z",
     "iopub.status.busy": "2024-03-11T02:43:24.078083Z",
     "iopub.status.idle": "2024-03-11T02:44:20.646960Z",
     "shell.execute_reply": "2024-03-11T02:44:20.645842Z"
    },
    "papermill": {
     "duration": 56.580512,
     "end_time": "2024-03-11T02:44:20.649420",
     "exception": false,
     "start_time": "2024-03-11T02:43:24.068908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading non-defended dataset for open-world scenario for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train loaded\n",
      "y_train loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_valid loaded\n",
      "y_valid loaded\n",
      "Data dimensions:\n",
      "X: Training data's shape :  (96000, 5000)\n",
      "y: Training data's shape :  (96000,)\n",
      "X: Validation data's shape :  (9600, 5000)\n",
      "y: Validation data's shape :  (9600,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any None values in X_train: False\n",
      "Any None values in y_train: False\n",
      "Any None values in X_valid: False\n",
      "Any None values in y_valid: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data dimensions:\n",
      "X: Merged data's shape :  (105600, 5000)\n",
      "y: Merged data's shape :  (105600,)\n",
      "Features of the merged dataset:\n",
      "[[-1. -1.  1. ...  0.  0.  0.]\n",
      " [-1.  1. -1. ...  0.  0.  0.]\n",
      " [-1.  1. -1. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 1.  1.  1. ...  0.  0.  0.]\n",
      " [ 1. -1.  1. ...  0.  0.  0.]\n",
      " [-1.  1.  1. ... -1. -1. -1.]]\n",
      "Features of the merged dataset:\n",
      "[80 83 95 ... 95 34 44]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import numpy as np  # Add this line\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, BatchNormalization\n",
    "from keras.layers import Activation, Flatten, Dense, Dropout, ReLU\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from keras import layers, models\n",
    "\n",
    "# Load data for non-defended dataset for OW training\n",
    "def LoadDataNoDefOW_Training():\n",
    "\n",
    "    print(\"Loading non-defended dataset for open-world scenario for training\")\n",
    "    # Point to the directory storing data\n",
    "    dataset_dir = '/kaggle/input/dataset-non-defended-open-world/'\n",
    "\n",
    "    # X represents a sequence of traffic directions\n",
    "    # y represents a sequence of corresponding label (website's label)\n",
    "\n",
    "    try:\n",
    "        # Load training data\n",
    "        with open(dataset_dir + 'X_train_NoDef.pkl', 'rb') as handle:\n",
    "            X_train = np.array(pickle.load(handle, encoding='latin1'))\n",
    "        print(\"X_train loaded\")\n",
    "        with open(dataset_dir + 'y_train_NoDef.pkl', 'rb') as handle:\n",
    "            y_train = np.array(pickle.load(handle, encoding='latin1'))\n",
    "        print(\"y_train loaded\")\n",
    "\n",
    "        # Load validation data\n",
    "        with open(dataset_dir + 'X_valid_NoDef.pkl', 'rb') as handle:\n",
    "            X_valid = np.array(pickle.load(handle, encoding='latin1'))\n",
    "        print(\"X_valid loaded\")\n",
    "        with open(dataset_dir + 'y_valid_NoDef.pkl', 'rb') as handle:\n",
    "            y_valid = np.array(pickle.load(handle, encoding='latin1'))\n",
    "        print(\"y_valid loaded\")\n",
    "\n",
    "        print(\"Data dimensions:\")\n",
    "        print(\"X: Training data's shape : \", X_train.shape)\n",
    "        print(\"y: Training data's shape : \", y_train.shape)\n",
    "        print(\"X: Validation data's shape : \", X_valid.shape)\n",
    "        print(\"y: Validation data's shape : \", y_valid.shape)\n",
    "        \n",
    "        print(\"Any None values in X_train:\", np.any(np.isnan(X_train)))\n",
    "        print(\"Any None values in y_train:\", np.any(np.isnan(y_train)))\n",
    "        print(\"Any None values in X_valid:\", np.any(np.isnan(X_valid)))\n",
    "        print(\"Any None values in y_valid:\", np.any(np.isnan(y_valid)))\n",
    "        \n",
    "        # Merge datasets\n",
    "        X_all = np.concatenate((X_train, X_valid), axis=0)\n",
    "        y_all = np.concatenate((y_train, y_valid), axis=0)\n",
    "\n",
    "        print(\"Merged data dimensions:\")\n",
    "        print(\"X: Merged data's shape : \", X_all.shape)\n",
    "        print(\"y: Merged data's shape : \", y_all.shape)\n",
    "        \n",
    "        # Print features of the merged dataset\n",
    "        print(\"Features of the merged dataset:\")\n",
    "        print(X_all)\n",
    "         # Print features of the merged dataset\n",
    "        print(\"Features of the merged dataset:\")\n",
    "        print(y_all)\n",
    "        \n",
    "       \n",
    "        return X_all, y_all\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", str(e))\n",
    "        return None\n",
    "\n",
    "# Call the function to load, merge, and balance data\n",
    "X_all, y_all = LoadDataNoDefOW_Training()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9631191a",
   "metadata": {
    "papermill": {
     "duration": 0.008292,
     "end_time": "2024-03-11T02:44:20.666650",
     "exception": false,
     "start_time": "2024-03-11T02:44:20.658358",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "********for 20 epoch****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8674e752",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T02:44:20.684034Z",
     "iopub.status.busy": "2024-03-11T02:44:20.683134Z",
     "iopub.status.idle": "2024-03-11T02:44:26.693311Z",
     "shell.execute_reply": "2024-03-11T02:44:26.692413Z"
    },
    "papermill": {
     "duration": 6.021066,
     "end_time": "2024-03-11T02:44:26.695527",
     "exception": false,
     "start_time": "2024-03-11T02:44:20.674461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading non-defended dataset for open-world scenario for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train loaded\n",
      "y_train loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_valid loaded\n",
      "y_valid loaded\n",
      "Data dimensions:\n",
      "X: Training data's shape :  (96000, 5000)\n",
      "y: Training data's shape :  (96000,)\n",
      "X: Validation data's shape :  (9600, 5000)\n",
      "y: Validation data's shape :  (9600,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any None values in X_train: False\n",
      "Any None values in y_train: False\n",
      "Any None values in X_valid: False\n",
      "Any None values in y_valid: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data dimensions:\n",
      "X: Merged data's shape :  (105600, 5000)\n",
      "y: Merged data's shape :  (105600,)\n",
      "Features of the merged dataset:\n",
      "[[-1. -1.  1. ...  0.  0.  0.]\n",
      " [-1.  1. -1. ...  0.  0.  0.]\n",
      " [-1.  1. -1. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 1.  1.  1. ...  0.  0.  0.]\n",
      " [ 1. -1.  1. ...  0.  0.  0.]\n",
      " [-1.  1.  1. ... -1. -1. -1.]]\n",
      "Features of the merged dataset:\n",
      "[80 83 95 ... 95 34 44]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import numpy as np  # Add this line\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, BatchNormalization\n",
    "from keras.layers import Activation, Flatten, Dense, Dropout, ELU\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from keras import layers, models\n",
    "\n",
    "# Load data for non-defended dataset for OW training\n",
    "def LoadDataNoDefOW_Training():\n",
    "\n",
    "    print(\"Loading non-defended dataset for open-world scenario for training\")\n",
    "    # Point to the directory storing data\n",
    "    dataset_dir = '/kaggle/input/dataset-non-defended-open-world/'\n",
    "\n",
    "    # X represents a sequence of traffic directions\n",
    "    # y represents a sequence of corresponding label (website's label)\n",
    "\n",
    "    try:\n",
    "        # Load training data\n",
    "        with open(dataset_dir + 'X_train_NoDef.pkl', 'rb') as handle:\n",
    "            X_train = np.array(pickle.load(handle, encoding='latin1'))\n",
    "        print(\"X_train loaded\")\n",
    "        with open(dataset_dir + 'y_train_NoDef.pkl', 'rb') as handle:\n",
    "            y_train = np.array(pickle.load(handle, encoding='latin1'))\n",
    "        print(\"y_train loaded\")\n",
    "\n",
    "        # Load validation data\n",
    "        with open(dataset_dir + 'X_valid_NoDef.pkl', 'rb') as handle:\n",
    "            X_valid = np.array(pickle.load(handle, encoding='latin1'))\n",
    "        print(\"X_valid loaded\")\n",
    "        with open(dataset_dir + 'y_valid_NoDef.pkl', 'rb') as handle:\n",
    "            y_valid = np.array(pickle.load(handle, encoding='latin1'))\n",
    "        print(\"y_valid loaded\")\n",
    "\n",
    "        print(\"Data dimensions:\")\n",
    "        print(\"X: Training data's shape : \", X_train.shape)\n",
    "        print(\"y: Training data's shape : \", y_train.shape)\n",
    "        print(\"X: Validation data's shape : \", X_valid.shape)\n",
    "        print(\"y: Validation data's shape : \", y_valid.shape)\n",
    "        \n",
    "        print(\"Any None values in X_train:\", np.any(np.isnan(X_train)))\n",
    "        print(\"Any None values in y_train:\", np.any(np.isnan(y_train)))\n",
    "        print(\"Any None values in X_valid:\", np.any(np.isnan(X_valid)))\n",
    "        print(\"Any None values in y_valid:\", np.any(np.isnan(y_valid)))\n",
    "        \n",
    "        # Merge datasets\n",
    "        X_all = np.concatenate((X_train, X_valid), axis=0)\n",
    "        y_all = np.concatenate((y_train, y_valid), axis=0)\n",
    "\n",
    "        print(\"Merged data dimensions:\")\n",
    "        print(\"X: Merged data's shape : \", X_all.shape)\n",
    "        print(\"y: Merged data's shape : \", y_all.shape)\n",
    "        \n",
    "        # Print features of the merged dataset\n",
    "        print(\"Features of the merged dataset:\")\n",
    "        print(X_all)\n",
    "         # Print features of the merged dataset\n",
    "        print(\"Features of the merged dataset:\")\n",
    "        print(y_all)\n",
    "        \n",
    "       \n",
    "        return X_all, y_all\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", str(e))\n",
    "        return None\n",
    "\n",
    "# Call the function to load, merge, and balance data\n",
    "X_all, y_all = LoadDataNoDefOW_Training()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2987acad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T02:44:26.714765Z",
     "iopub.status.busy": "2024-03-11T02:44:26.714461Z",
     "iopub.status.idle": "2024-03-11T05:10:16.702460Z",
     "shell.execute_reply": "2024-03-11T05:10:16.701380Z"
    },
    "papermill": {
     "duration": 8750.000695,
     "end_time": "2024-03-11T05:10:16.704631",
     "exception": false,
     "start_time": "2024-03-11T02:44:26.703936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model built successfully.\n",
      "Model Summary:\n",
      "Model: \"sequential\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Layer (type)                Output Shape              Param #   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block1_conv1 (Conv1D)       (None, 5000, 32)          288       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch_normalization_1 (Bat  (None, 5000, 32)          128       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " chNormalization)                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block1_adv_act1 (Activatio  (None, 5000, 32)          0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " n)                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block1_conv2 (Conv1D)       (None, 5000, 32)          8224      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch_normalization_2 (Bat  (None, 5000, 32)          128       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " chNormalization)                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block1_adv_act2 (Activatio  (None, 5000, 32)          0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " n)                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block1_pool (MaxPooling1D)  (None, 1250, 32)          0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block1_dropout (Dropout)    (None, 1250, 32)          0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block2_conv1 (Conv1D)       (None, 1250, 64)          16448     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch_normalization_3 (Bat  (None, 1250, 64)          256       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " chNormalization)                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block2_adv_act1 (Activatio  (None, 1250, 64)          0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " n)                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block2_conv2 (Conv1D)       (None, 1250, 64)          32832     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch_normalization_4 (Bat  (None, 1250, 64)          256       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " chNormalization)                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block2_adv_act2 (Activatio  (None, 1250, 64)          0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " n)                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block2_pool (MaxPooling1D)  (None, 313, 64)           0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block2_dropout (Dropout)    (None, 313, 64)           0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block3_conv1 (Conv1D)       (None, 313, 128)          65664     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch_normalization_5 (Bat  (None, 313, 128)          512       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " chNormalization)                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block3_adv_act1 (Activatio  (None, 313, 128)          0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " n)                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block3_conv2 (Conv1D)       (None, 313, 128)          131200    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch_normalization_6 (Bat  (None, 313, 128)          512       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " chNormalization)                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block3_adv_act2 (Activatio  (None, 313, 128)          0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " n)                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block3_pool (MaxPooling1D)  (None, 79, 128)           0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block3_dropout (Dropout)    (None, 79, 128)           0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " flatten (Flatten)           (None, 10112)             0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " fc1 (Dense)                 (None, 512)               5177856   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch_normalization_9 (Bat  (None, 512)               2048      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " chNormalization)                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " fc1_act (Activation)        (None, 512)               0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " fc1_dropout (Dropout)       (None, 512)               0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " fc2 (Dense)                 (None, 512)               262656    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch_normalization_10 (Ba  (None, 512)               2048      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " tchNormalization)                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " fc2_act (Activation)        (None, 512)               0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " fc2_dropout (Dropout)       (None, 512)               0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " fc_final (Dense)            (None, 96)                49248     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " softmax (Activation)        (None, 96)                0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 5750304 (21.94 MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 5747360 (21.92 MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-trainable params: 2944 (11.50 KB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading non-defended dataset for open-world scenario for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train loaded\n",
      "y_train loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_valid loaded\n",
      "y_valid loaded\n",
      "Data dimensions:\n",
      "X: Training data's shape :  (96000, 5000)\n",
      "y: Training data's shape :  (96000,)\n",
      "X: Validation data's shape :  (9600, 5000)\n",
      "y: Validation data's shape :  (9600,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any None values in X_train: False\n",
      "Any None values in y_train: False\n",
      "Any None values in X_valid: False\n",
      "Any None values in y_valid: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data dimensions:\n",
      "X: Merged data's shape :  (105600, 5000)\n",
      "y: Merged data's shape :  (105600,)\n",
      "Features of the merged dataset:\n",
      "[[-1. -1.  1. ...  0.  0.  0.]\n",
      " [-1.  1. -1. ...  0.  0.  0.]\n",
      " [-1.  1. -1. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 1.  1.  1. ...  0.  0.  0.]\n",
      " [ 1. -1.  1. ...  0.  0.  0.]\n",
      " [-1.  1.  1. ... -1. -1. -1.]]\n",
      "Features of the merged dataset:\n",
      "[80 83 95 ... 95 34 44]\n",
      "\n",
      "Training on Fold 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 94s - loss: 0.8560 - accuracy: 0.7812 - val_loss: 0.3020 - val_accuracy: 0.9202 - 94s/epoch - 72ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.3320 - accuracy: 0.9111 - val_loss: 0.2216 - val_accuracy: 0.9424 - 85s/epoch - 64ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.2533 - accuracy: 0.9309 - val_loss: 0.1995 - val_accuracy: 0.9457 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.2107 - accuracy: 0.9410 - val_loss: 0.1836 - val_accuracy: 0.9525 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1810 - accuracy: 0.9488 - val_loss: 0.1650 - val_accuracy: 0.9552 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1583 - accuracy: 0.9550 - val_loss: 0.1601 - val_accuracy: 0.9574 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1386 - accuracy: 0.9601 - val_loss: 0.1517 - val_accuracy: 0.9611 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1305 - accuracy: 0.9626 - val_loss: 0.1591 - val_accuracy: 0.9630 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1160 - accuracy: 0.9663 - val_loss: 0.1644 - val_accuracy: 0.9581 - 85s/epoch - 64ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1091 - accuracy: 0.9679 - val_loss: 0.1478 - val_accuracy: 0.9619 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1028 - accuracy: 0.9700 - val_loss: 0.1573 - val_accuracy: 0.9617 - 85s/epoch - 64ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0984 - accuracy: 0.9717 - val_loss: 0.1481 - val_accuracy: 0.9637 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0876 - accuracy: 0.9748 - val_loss: 0.1629 - val_accuracy: 0.9612 - 85s/epoch - 64ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0851 - accuracy: 0.9759 - val_loss: 0.1459 - val_accuracy: 0.9665 - 85s/epoch - 64ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0822 - accuracy: 0.9754 - val_loss: 0.1446 - val_accuracy: 0.9656 - 85s/epoch - 64ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0798 - accuracy: 0.9771 - val_loss: 0.1479 - val_accuracy: 0.9653 - 85s/epoch - 64ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0760 - accuracy: 0.9782 - val_loss: 0.1428 - val_accuracy: 0.9679 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0735 - accuracy: 0.9782 - val_loss: 0.1381 - val_accuracy: 0.9683 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0687 - accuracy: 0.9805 - val_loss: 0.1350 - val_accuracy: 0.9681 - 85s/epoch - 64ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0655 - accuracy: 0.9810 - val_loss: 0.1545 - val_accuracy: 0.9677 - 85s/epoch - 64ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "660/660 - 6s - loss: 0.1545 - accuracy: 0.9677 - 6s/epoch - 10ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1 - Test Accuracy: 96.77%\n",
      "\n",
      "Training on Fold 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 92s - loss: 0.8508 - accuracy: 0.7831 - val_loss: 0.3562 - val_accuracy: 0.9011 - 92s/epoch - 70ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.3357 - accuracy: 0.9108 - val_loss: 0.2589 - val_accuracy: 0.9290 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.2502 - accuracy: 0.9322 - val_loss: 0.1862 - val_accuracy: 0.9491 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.2118 - accuracy: 0.9404 - val_loss: 0.1661 - val_accuracy: 0.9556 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1830 - accuracy: 0.9477 - val_loss: 0.1758 - val_accuracy: 0.9513 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1584 - accuracy: 0.9553 - val_loss: 0.1600 - val_accuracy: 0.9574 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1419 - accuracy: 0.9594 - val_loss: 0.1588 - val_accuracy: 0.9581 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1278 - accuracy: 0.9637 - val_loss: 0.1381 - val_accuracy: 0.9635 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1195 - accuracy: 0.9662 - val_loss: 0.1438 - val_accuracy: 0.9635 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1110 - accuracy: 0.9685 - val_loss: 0.1553 - val_accuracy: 0.9608 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1041 - accuracy: 0.9700 - val_loss: 0.1420 - val_accuracy: 0.9648 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1012 - accuracy: 0.9710 - val_loss: 0.1645 - val_accuracy: 0.9553 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0878 - accuracy: 0.9748 - val_loss: 0.1481 - val_accuracy: 0.9616 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0862 - accuracy: 0.9751 - val_loss: 0.1588 - val_accuracy: 0.9592 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0844 - accuracy: 0.9756 - val_loss: 0.1416 - val_accuracy: 0.9648 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0779 - accuracy: 0.9773 - val_loss: 0.1434 - val_accuracy: 0.9644 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0739 - accuracy: 0.9787 - val_loss: 0.1645 - val_accuracy: 0.9604 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0747 - accuracy: 0.9790 - val_loss: 0.1352 - val_accuracy: 0.9673 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0704 - accuracy: 0.9796 - val_loss: 0.1409 - val_accuracy: 0.9674 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0646 - accuracy: 0.9812 - val_loss: 0.1323 - val_accuracy: 0.9686 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "660/660 - 6s - loss: 0.1323 - accuracy: 0.9686 - 6s/epoch - 9ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 2 - Test Accuracy: 96.86%\n",
      "\n",
      "Training on Fold 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 92s - loss: 0.8468 - accuracy: 0.7844 - val_loss: 0.3214 - val_accuracy: 0.9136 - 92s/epoch - 70ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.3374 - accuracy: 0.9088 - val_loss: 0.2608 - val_accuracy: 0.9255 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.2524 - accuracy: 0.9307 - val_loss: 0.1736 - val_accuracy: 0.9537 - 85s/epoch - 64ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.2144 - accuracy: 0.9399 - val_loss: 0.1614 - val_accuracy: 0.9563 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1828 - accuracy: 0.9487 - val_loss: 0.1578 - val_accuracy: 0.9561 - 85s/epoch - 64ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1618 - accuracy: 0.9542 - val_loss: 0.1589 - val_accuracy: 0.9573 - 85s/epoch - 64ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1451 - accuracy: 0.9590 - val_loss: 0.1299 - val_accuracy: 0.9651 - 85s/epoch - 64ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1297 - accuracy: 0.9630 - val_loss: 0.1532 - val_accuracy: 0.9589 - 85s/epoch - 64ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1221 - accuracy: 0.9648 - val_loss: 0.1356 - val_accuracy: 0.9651 - 85s/epoch - 64ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1104 - accuracy: 0.9678 - val_loss: 0.1428 - val_accuracy: 0.9622 - 85s/epoch - 64ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1059 - accuracy: 0.9692 - val_loss: 0.1391 - val_accuracy: 0.9637 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0969 - accuracy: 0.9721 - val_loss: 0.1327 - val_accuracy: 0.9659 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0900 - accuracy: 0.9737 - val_loss: 0.1391 - val_accuracy: 0.9647 - 85s/epoch - 64ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0892 - accuracy: 0.9744 - val_loss: 0.1305 - val_accuracy: 0.9680 - 85s/epoch - 64ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0828 - accuracy: 0.9762 - val_loss: 0.1393 - val_accuracy: 0.9660 - 85s/epoch - 64ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0802 - accuracy: 0.9767 - val_loss: 0.1309 - val_accuracy: 0.9689 - 85s/epoch - 64ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0782 - accuracy: 0.9775 - val_loss: 0.1188 - val_accuracy: 0.9704 - 85s/epoch - 64ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0731 - accuracy: 0.9790 - val_loss: 0.1415 - val_accuracy: 0.9648 - 85s/epoch - 64ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0709 - accuracy: 0.9800 - val_loss: 0.1265 - val_accuracy: 0.9690 - 85s/epoch - 64ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0690 - accuracy: 0.9799 - val_loss: 0.1257 - val_accuracy: 0.9705 - 85s/epoch - 64ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "660/660 - 6s - loss: 0.1257 - accuracy: 0.9705 - 6s/epoch - 10ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 3 - Test Accuracy: 97.05%\n",
      "\n",
      "Training on Fold 4/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 93s - loss: 0.8498 - accuracy: 0.7852 - val_loss: 0.3087 - val_accuracy: 0.9191 - 93s/epoch - 70ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.3376 - accuracy: 0.9095 - val_loss: 0.2468 - val_accuracy: 0.9334 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.2627 - accuracy: 0.9285 - val_loss: 0.1882 - val_accuracy: 0.9491 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.2153 - accuracy: 0.9398 - val_loss: 0.1668 - val_accuracy: 0.9557 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1862 - accuracy: 0.9472 - val_loss: 0.1870 - val_accuracy: 0.9500 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1629 - accuracy: 0.9541 - val_loss: 0.1832 - val_accuracy: 0.9516 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1496 - accuracy: 0.9569 - val_loss: 0.1594 - val_accuracy: 0.9567 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1348 - accuracy: 0.9616 - val_loss: 0.1698 - val_accuracy: 0.9590 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1194 - accuracy: 0.9655 - val_loss: 0.1475 - val_accuracy: 0.9621 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1146 - accuracy: 0.9669 - val_loss: 0.1468 - val_accuracy: 0.9624 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1061 - accuracy: 0.9691 - val_loss: 0.1377 - val_accuracy: 0.9645 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0995 - accuracy: 0.9718 - val_loss: 0.1549 - val_accuracy: 0.9611 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0938 - accuracy: 0.9724 - val_loss: 0.1290 - val_accuracy: 0.9683 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0881 - accuracy: 0.9739 - val_loss: 0.1336 - val_accuracy: 0.9686 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0842 - accuracy: 0.9754 - val_loss: 0.1251 - val_accuracy: 0.9699 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0813 - accuracy: 0.9764 - val_loss: 0.1484 - val_accuracy: 0.9625 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0747 - accuracy: 0.9780 - val_loss: 0.1401 - val_accuracy: 0.9676 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0769 - accuracy: 0.9777 - val_loss: 0.1378 - val_accuracy: 0.9687 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0721 - accuracy: 0.9797 - val_loss: 0.1332 - val_accuracy: 0.9689 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0691 - accuracy: 0.9800 - val_loss: 0.1369 - val_accuracy: 0.9686 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "660/660 - 6s - loss: 0.1369 - accuracy: 0.9686 - 6s/epoch - 10ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 4 - Test Accuracy: 96.86%\n",
      "\n",
      "Training on Fold 5/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 93s - loss: 0.8549 - accuracy: 0.7801 - val_loss: 0.2934 - val_accuracy: 0.9230 - 93s/epoch - 70ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.3394 - accuracy: 0.9097 - val_loss: 0.2343 - val_accuracy: 0.9377 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.2579 - accuracy: 0.9292 - val_loss: 0.1868 - val_accuracy: 0.9510 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.2145 - accuracy: 0.9406 - val_loss: 0.1966 - val_accuracy: 0.9473 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1859 - accuracy: 0.9478 - val_loss: 0.1607 - val_accuracy: 0.9571 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1636 - accuracy: 0.9531 - val_loss: 0.1564 - val_accuracy: 0.9586 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1423 - accuracy: 0.9591 - val_loss: 0.1592 - val_accuracy: 0.9592 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1303 - accuracy: 0.9623 - val_loss: 0.1471 - val_accuracy: 0.9620 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1217 - accuracy: 0.9641 - val_loss: 0.1641 - val_accuracy: 0.9600 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1117 - accuracy: 0.9674 - val_loss: 0.1517 - val_accuracy: 0.9618 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1059 - accuracy: 0.9698 - val_loss: 0.1482 - val_accuracy: 0.9635 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0995 - accuracy: 0.9712 - val_loss: 0.1532 - val_accuracy: 0.9624 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0946 - accuracy: 0.9728 - val_loss: 0.1524 - val_accuracy: 0.9639 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0880 - accuracy: 0.9744 - val_loss: 0.1458 - val_accuracy: 0.9642 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0821 - accuracy: 0.9764 - val_loss: 0.1373 - val_accuracy: 0.9665 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0789 - accuracy: 0.9767 - val_loss: 0.1442 - val_accuracy: 0.9652 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0745 - accuracy: 0.9783 - val_loss: 0.1464 - val_accuracy: 0.9677 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0752 - accuracy: 0.9776 - val_loss: 0.1605 - val_accuracy: 0.9657 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0714 - accuracy: 0.9791 - val_loss: 0.1406 - val_accuracy: 0.9688 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0700 - accuracy: 0.9795 - val_loss: 0.1511 - val_accuracy: 0.9658 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "660/660 - 6s - loss: 0.1511 - accuracy: 0.9658 - 6s/epoch - 9ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 5 - Test Accuracy: 96.58%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model saved successfully at: /kaggle/working/DFNet_OpenWorld_NoDef.keras\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, BatchNormalization\n",
    "from keras.layers import Activation, Flatten, Dense, Dropout, ReLU\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from keras import layers, models\n",
    "import numpy as np\n",
    "from keras.layers import Activation\n",
    "\n",
    "class DFNet:\n",
    "    @staticmethod\n",
    "    def build(input_shape, classes, dropout_rate1=0.3, dropout_rate2=0.5, dropout_rate_fc=0.7):\n",
    "        model = Sequential()\n",
    "\n",
    "        # ... (previous model definition remains unchanged)\n",
    "        # Block 1\n",
    "        filter_num = [None,32, 64, 128, 256]\n",
    "        kernel_size = [None, 8, 8, 8, 8]\n",
    "        conv_stride_size = [None, 1, 1, 1, 1]\n",
    "        pool_stride_size = [None, 4, 4, 4, 4]\n",
    "        pool_size = [None, 8, 8, 8, 8]\n",
    "\n",
    "        for i in range(1, 4):\n",
    "            model.add(Conv1D(filters=filter_num[i], kernel_size=kernel_size[i],\n",
    "                             strides=conv_stride_size[i], padding='same',\n",
    "                             input_shape=input_shape if i == 1 else (None, input_shape[1]),\n",
    "                             name=f'block{i}_conv1'))\n",
    "            model.add(BatchNormalization(name=f'batch_normalization_{i * 2 - 1}'))\n",
    "            model.add(Activation('relu', name=f'block{i}_adv_act1'))\n",
    "            model.add(Conv1D(filters=filter_num[i], kernel_size=kernel_size[i],\n",
    "                             strides=conv_stride_size[i], padding='same',\n",
    "                             name=f'block{i}_conv2'))\n",
    "            model.add(BatchNormalization(name=f'batch_normalization_{i * 2}'))\n",
    "            model.add(Activation('relu', name=f'block{i}_adv_act2'))\n",
    "\n",
    "            model.add(MaxPooling1D(pool_size=pool_size[i], strides=pool_stride_size[i],\n",
    "                                   padding='same', name=f'block{i}_pool'))\n",
    "            model.add(Dropout(0.1, name=f'block{i}_dropout'))\n",
    "\n",
    "        # ... (rest of the model remains unchanged)\n",
    "\n",
    "        model.add(Flatten(name='flatten'))\n",
    "\n",
    "        # Fully connected layers\n",
    "        for i in range(1, 3):\n",
    "            model.add(Dense(512, kernel_initializer=glorot_uniform(seed=0), name=f'fc{i}'))\n",
    "            model.add(BatchNormalization(name=f'batch_normalization_{i + 8}'))\n",
    "            model.add(Activation('relu', name=f'fc{i}_act'))\n",
    "\n",
    "            # Experiment with different dropout rates\n",
    "            model.add(Dropout(dropout_rate_fc, name=f'fc{i}_dropout'))\n",
    "\n",
    "        # Output layer\n",
    "        model.add(Dense(classes, kernel_initializer=glorot_uniform(seed=0), name='fc_final'))\n",
    "        model.add(Activation('softmax', name=\"softmax\"))\n",
    "\n",
    "        print(\"Model built successfully.\")\n",
    "        return model\n",
    "    # Assuming input_shape and num_classes are defined as follows (adjust based on your actual data)\n",
    "input_shape = (5000, 1)\n",
    "num_classes = 96\n",
    "\n",
    "# Experiment with different dropout rates\n",
    "dropout_rate1 = 0.6\n",
    "dropout_rate2 = 0.5\n",
    "dropout_rate_fc = 0.4\n",
    "\n",
    "# Build the model with the specified dropout rates\n",
    "model = DFNet.build(input_shape=input_shape, classes=num_classes,\n",
    "                    dropout_rate1=dropout_rate1, dropout_rate2=dropout_rate2, dropout_rate_fc=dropout_rate_fc)\n",
    "\n",
    "\n",
    "# Print the model summary\n",
    "print(\"Model Summary:\")\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Assuming input_shape and num_classes are defined as follows (adjust based on your actual data)\n",
    "input_shape = (5000, 1)\n",
    "num_classes = 96\n",
    "\n",
    "# Experiment with different dropout rates\n",
    "dropout_rate1 = 0.6\n",
    "dropout_rate2 = 0.5\n",
    "dropout_rate_fc = 0.4\n",
    "\n",
    "# Load and merge data using the function you defined\n",
    "X_all, y_all = LoadDataNoDefOW_Training()\n",
    "# Define the number of folds\n",
    "n_splits = 5  # You can adjust this as needed\n",
    "\n",
    "# Initialize Stratified K-Fold\n",
    "stratkf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store results\n",
    "all_histories = []\n",
    "\n",
    "# Iterate over folds\n",
    "for fold, (train_index, test_index) in enumerate(stratkf.split(X_all, y_all)):\n",
    "    print(f\"\\nTraining on Fold {fold + 1}/{n_splits}\")\n",
    "\n",
    "    # Split the data\n",
    "    X_train, X_test = X_all[train_index], X_all[test_index]\n",
    "    y_train, y_test = y_all[train_index], y_all[test_index]\n",
    "    \n",
    "        # Build the model\n",
    "    model = DFNet.build(input_shape=input_shape, classes=num_classes,\n",
    "                        dropout_rate1=dropout_rate1, dropout_rate2=dropout_rate2, dropout_rate_fc=dropout_rate_fc)\n",
    "\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "     # Define early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "    # Train the model with early stopping\n",
    "    history = model.fit(X_train, y_train, epochs=20, batch_size=64, \n",
    "                        validation_data=(X_test, y_test), verbose=2, callbacks=[early_stopping])\n",
    "    \n",
    "   \n",
    "\n",
    "\n",
    "    # Train the model\n",
    "    #history = model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test), verbose=2)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
    "    print(f\"\\nFold {fold + 1} - Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    # Save history for later analysis if needed\n",
    "    all_histories.append(history)\n",
    "    # Check unique labels in y_train\n",
    "    \n",
    "    # Update num_classes based on the actual number of unique classes in your dataset\n",
    "#num_classes = len(np.unique(y_all))\n",
    "saved_path_keras = '/kaggle/working/DFNet_OpenWorld_NoDef.keras'\n",
    "model.save(saved_path_keras)\n",
    "\n",
    "print(\"Trained model saved successfully at:\", saved_path_keras)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a54d7ae3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T05:10:16.770966Z",
     "iopub.status.busy": "2024-03-11T05:10:16.770651Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2024-03-11T05:10:16.737610",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model built successfully.\n",
      "Model Summary:\n",
      "Model: \"sequential_6\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Layer (type)                Output Shape              Param #   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block1_conv1 (Conv1D)       (None, 5000, 32)          288       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch_normalization_1 (Bat  (None, 5000, 32)          128       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " chNormalization)                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block1_adv_act1 (Activatio  (None, 5000, 32)          0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " n)                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block1_conv2 (Conv1D)       (None, 5000, 32)          8224      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch_normalization_2 (Bat  (None, 5000, 32)          128       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " chNormalization)                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block1_adv_act2 (Activatio  (None, 5000, 32)          0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " n)                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block1_pool (MaxPooling1D)  (None, 1250, 32)          0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block1_dropout (Dropout)    (None, 1250, 32)          0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block2_conv1 (Conv1D)       (None, 1250, 64)          16448     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch_normalization_3 (Bat  (None, 1250, 64)          256       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " chNormalization)                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block2_adv_act1 (Activatio  (None, 1250, 64)          0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " n)                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block2_conv2 (Conv1D)       (None, 1250, 64)          32832     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch_normalization_4 (Bat  (None, 1250, 64)          256       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " chNormalization)                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block2_adv_act2 (Activatio  (None, 1250, 64)          0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " n)                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block2_pool (MaxPooling1D)  (None, 313, 64)           0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block2_dropout (Dropout)    (None, 313, 64)           0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block3_conv1 (Conv1D)       (None, 313, 128)          65664     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch_normalization_5 (Bat  (None, 313, 128)          512       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " chNormalization)                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block3_adv_act1 (Activatio  (None, 313, 128)          0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " n)                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block3_conv2 (Conv1D)       (None, 313, 128)          131200    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch_normalization_6 (Bat  (None, 313, 128)          512       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " chNormalization)                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block3_adv_act2 (Activatio  (None, 313, 128)          0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " n)                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block3_pool (MaxPooling1D)  (None, 79, 128)           0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block3_dropout (Dropout)    (None, 79, 128)           0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " flatten (Flatten)           (None, 10112)             0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " fc1 (Dense)                 (None, 512)               5177856   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch_normalization_9 (Bat  (None, 512)               2048      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " chNormalization)                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " fc1_act (Activation)        (None, 512)               0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " fc1_dropout (Dropout)       (None, 512)               0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " fc2 (Dense)                 (None, 512)               262656    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch_normalization_10 (Ba  (None, 512)               2048      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " tchNormalization)                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " fc2_act (Activation)        (None, 512)               0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " fc2_dropout (Dropout)       (None, 512)               0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " fc_final (Dense)            (None, 96)                49248     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " softmax (Activation)        (None, 96)                0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 5750304 (21.94 MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 5747360 (21.92 MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-trainable params: 2944 (11.50 KB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading non-defended dataset for open-world scenario for training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train loaded\n",
      "y_train loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_valid loaded\n",
      "y_valid loaded\n",
      "Data dimensions:\n",
      "X: Training data's shape :  (96000, 5000)\n",
      "y: Training data's shape :  (96000,)\n",
      "X: Validation data's shape :  (9600, 5000)\n",
      "y: Validation data's shape :  (9600,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any None values in X_train: False\n",
      "Any None values in y_train: False\n",
      "Any None values in X_valid: False\n",
      "Any None values in y_valid: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data dimensions:\n",
      "X: Merged data's shape :  (105600, 5000)\n",
      "y: Merged data's shape :  (105600,)\n",
      "Features of the merged dataset:\n",
      "[[-1. -1.  1. ...  0.  0.  0.]\n",
      " [-1.  1. -1. ...  0.  0.  0.]\n",
      " [-1.  1. -1. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 1.  1.  1. ...  0.  0.  0.]\n",
      " [ 1. -1.  1. ...  0.  0.  0.]\n",
      " [-1.  1.  1. ... -1. -1. -1.]]\n",
      "Features of the merged dataset:\n",
      "[80 83 95 ... 95 34 44]\n",
      "\n",
      "Training on Fold 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 93s - loss: 0.8471 - accuracy: 0.7827 - val_loss: 0.3012 - val_accuracy: 0.9207 - 93s/epoch - 70ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.3362 - accuracy: 0.9086 - val_loss: 0.2350 - val_accuracy: 0.9384 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.2587 - accuracy: 0.9294 - val_loss: 0.2384 - val_accuracy: 0.9358 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.2160 - accuracy: 0.9396 - val_loss: 0.1891 - val_accuracy: 0.9512 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1856 - accuracy: 0.9475 - val_loss: 0.1750 - val_accuracy: 0.9542 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1637 - accuracy: 0.9542 - val_loss: 0.1764 - val_accuracy: 0.9550 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1465 - accuracy: 0.9578 - val_loss: 0.1689 - val_accuracy: 0.9568 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1383 - accuracy: 0.9597 - val_loss: 0.1607 - val_accuracy: 0.9582 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1236 - accuracy: 0.9639 - val_loss: 0.1516 - val_accuracy: 0.9620 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1129 - accuracy: 0.9673 - val_loss: 0.1489 - val_accuracy: 0.9609 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1050 - accuracy: 0.9696 - val_loss: 0.1786 - val_accuracy: 0.9564 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0986 - accuracy: 0.9718 - val_loss: 0.1564 - val_accuracy: 0.9596 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0926 - accuracy: 0.9729 - val_loss: 0.1347 - val_accuracy: 0.9670 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0901 - accuracy: 0.9746 - val_loss: 0.1435 - val_accuracy: 0.9649 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0853 - accuracy: 0.9749 - val_loss: 0.1366 - val_accuracy: 0.9668 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0813 - accuracy: 0.9765 - val_loss: 0.1472 - val_accuracy: 0.9652 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0774 - accuracy: 0.9773 - val_loss: 0.1417 - val_accuracy: 0.9682 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0757 - accuracy: 0.9777 - val_loss: 0.1493 - val_accuracy: 0.9659 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0723 - accuracy: 0.9793 - val_loss: 0.1548 - val_accuracy: 0.9666 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0696 - accuracy: 0.9797 - val_loss: 0.1456 - val_accuracy: 0.9679 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0689 - accuracy: 0.9804 - val_loss: 0.1630 - val_accuracy: 0.9655 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0651 - accuracy: 0.9812 - val_loss: 0.1399 - val_accuracy: 0.9677 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0623 - accuracy: 0.9818 - val_loss: 0.1429 - val_accuracy: 0.9664 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0615 - accuracy: 0.9825 - val_loss: 0.1314 - val_accuracy: 0.9697 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0586 - accuracy: 0.9829 - val_loss: 0.1363 - val_accuracy: 0.9712 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "660/660 - 6s - loss: 0.1363 - accuracy: 0.9712 - 6s/epoch - 10ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1 - Test Accuracy: 97.12%\n",
      "\n",
      "Training on Fold 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 92s - loss: 0.8636 - accuracy: 0.7805 - val_loss: 0.3712 - val_accuracy: 0.9027 - 92s/epoch - 70ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.3455 - accuracy: 0.9074 - val_loss: 0.2261 - val_accuracy: 0.9386 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.2641 - accuracy: 0.9264 - val_loss: 0.1917 - val_accuracy: 0.9494 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.2152 - accuracy: 0.9397 - val_loss: 0.2051 - val_accuracy: 0.9432 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1877 - accuracy: 0.9470 - val_loss: 0.1741 - val_accuracy: 0.9522 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1653 - accuracy: 0.9525 - val_loss: 0.1616 - val_accuracy: 0.9573 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1459 - accuracy: 0.9573 - val_loss: 0.1946 - val_accuracy: 0.9483 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1315 - accuracy: 0.9620 - val_loss: 0.1540 - val_accuracy: 0.9601 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1191 - accuracy: 0.9657 - val_loss: 0.1520 - val_accuracy: 0.9609 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1133 - accuracy: 0.9672 - val_loss: 0.1561 - val_accuracy: 0.9608 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1060 - accuracy: 0.9692 - val_loss: 0.1570 - val_accuracy: 0.9592 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0966 - accuracy: 0.9718 - val_loss: 0.1494 - val_accuracy: 0.9623 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0912 - accuracy: 0.9739 - val_loss: 0.1332 - val_accuracy: 0.9664 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0881 - accuracy: 0.9739 - val_loss: 0.1401 - val_accuracy: 0.9645 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0828 - accuracy: 0.9758 - val_loss: 0.1458 - val_accuracy: 0.9647 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0810 - accuracy: 0.9762 - val_loss: 0.1623 - val_accuracy: 0.9613 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0764 - accuracy: 0.9777 - val_loss: 0.1390 - val_accuracy: 0.9674 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0734 - accuracy: 0.9788 - val_loss: 0.1416 - val_accuracy: 0.9659 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0723 - accuracy: 0.9795 - val_loss: 0.1343 - val_accuracy: 0.9679 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0679 - accuracy: 0.9798 - val_loss: 0.1422 - val_accuracy: 0.9669 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0676 - accuracy: 0.9808 - val_loss: 0.1361 - val_accuracy: 0.9675 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0641 - accuracy: 0.9810 - val_loss: 0.1366 - val_accuracy: 0.9697 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0604 - accuracy: 0.9827 - val_loss: 0.1313 - val_accuracy: 0.9696 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0605 - accuracy: 0.9823 - val_loss: 0.1376 - val_accuracy: 0.9674 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0609 - accuracy: 0.9830 - val_loss: 0.1314 - val_accuracy: 0.9685 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "660/660 - 6s - loss: 0.1314 - accuracy: 0.9685 - 6s/epoch - 9ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 2 - Test Accuracy: 96.85%\n",
      "\n",
      "Training on Fold 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 93s - loss: 0.8232 - accuracy: 0.7906 - val_loss: 0.3107 - val_accuracy: 0.9130 - 93s/epoch - 70ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.3353 - accuracy: 0.9097 - val_loss: 0.2209 - val_accuracy: 0.9402 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.2600 - accuracy: 0.9291 - val_loss: 0.1975 - val_accuracy: 0.9448 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.2091 - accuracy: 0.9426 - val_loss: 0.1568 - val_accuracy: 0.9607 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1848 - accuracy: 0.9476 - val_loss: 0.1558 - val_accuracy: 0.9587 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1604 - accuracy: 0.9545 - val_loss: 0.1589 - val_accuracy: 0.9578 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1438 - accuracy: 0.9590 - val_loss: 0.1393 - val_accuracy: 0.9632 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1325 - accuracy: 0.9622 - val_loss: 0.1377 - val_accuracy: 0.9656 - 85s/epoch - 64ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1216 - accuracy: 0.9652 - val_loss: 0.1394 - val_accuracy: 0.9631 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1116 - accuracy: 0.9686 - val_loss: 0.1349 - val_accuracy: 0.9655 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1050 - accuracy: 0.9690 - val_loss: 0.1359 - val_accuracy: 0.9657 - 85s/epoch - 64ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0978 - accuracy: 0.9720 - val_loss: 0.1316 - val_accuracy: 0.9670 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0921 - accuracy: 0.9738 - val_loss: 0.1489 - val_accuracy: 0.9636 - 85s/epoch - 64ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0882 - accuracy: 0.9741 - val_loss: 0.1329 - val_accuracy: 0.9686 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0820 - accuracy: 0.9760 - val_loss: 0.1479 - val_accuracy: 0.9664 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0816 - accuracy: 0.9766 - val_loss: 0.1368 - val_accuracy: 0.9661 - 85s/epoch - 64ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0762 - accuracy: 0.9781 - val_loss: 0.1351 - val_accuracy: 0.9679 - 85s/epoch - 64ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0743 - accuracy: 0.9789 - val_loss: 0.1363 - val_accuracy: 0.9680 - 85s/epoch - 64ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0723 - accuracy: 0.9791 - val_loss: 0.1380 - val_accuracy: 0.9677 - 85s/epoch - 64ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0712 - accuracy: 0.9799 - val_loss: 0.1645 - val_accuracy: 0.9615 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0652 - accuracy: 0.9811 - val_loss: 0.1370 - val_accuracy: 0.9665 - 85s/epoch - 64ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0647 - accuracy: 0.9812 - val_loss: 0.1296 - val_accuracy: 0.9680 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0607 - accuracy: 0.9825 - val_loss: 0.1343 - val_accuracy: 0.9691 - 85s/epoch - 64ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0603 - accuracy: 0.9826 - val_loss: 0.1455 - val_accuracy: 0.9685 - 85s/epoch - 64ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0594 - accuracy: 0.9830 - val_loss: 0.1267 - val_accuracy: 0.9714 - 85s/epoch - 64ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "660/660 - 6s - loss: 0.1267 - accuracy: 0.9714 - 6s/epoch - 9ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 3 - Test Accuracy: 97.14%\n",
      "\n",
      "Training on Fold 4/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 93s - loss: 0.8711 - accuracy: 0.7774 - val_loss: 0.2938 - val_accuracy: 0.9223 - 93s/epoch - 71ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.3433 - accuracy: 0.9072 - val_loss: 0.2233 - val_accuracy: 0.9408 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.2639 - accuracy: 0.9270 - val_loss: 0.2648 - val_accuracy: 0.9277 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.2167 - accuracy: 0.9404 - val_loss: 0.2001 - val_accuracy: 0.9452 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1877 - accuracy: 0.9475 - val_loss: 0.1586 - val_accuracy: 0.9574 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1644 - accuracy: 0.9532 - val_loss: 0.1657 - val_accuracy: 0.9570 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1473 - accuracy: 0.9579 - val_loss: 0.1891 - val_accuracy: 0.9527 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1354 - accuracy: 0.9606 - val_loss: 0.1551 - val_accuracy: 0.9583 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1219 - accuracy: 0.9645 - val_loss: 0.1555 - val_accuracy: 0.9624 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1135 - accuracy: 0.9675 - val_loss: 0.1396 - val_accuracy: 0.9636 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1048 - accuracy: 0.9697 - val_loss: 0.1419 - val_accuracy: 0.9633 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.1033 - accuracy: 0.9707 - val_loss: 0.1397 - val_accuracy: 0.9651 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0925 - accuracy: 0.9734 - val_loss: 0.1559 - val_accuracy: 0.9606 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0900 - accuracy: 0.9741 - val_loss: 0.1319 - val_accuracy: 0.9672 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0848 - accuracy: 0.9757 - val_loss: 0.1724 - val_accuracy: 0.9563 - 85s/epoch - 64ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0817 - accuracy: 0.9763 - val_loss: 0.1441 - val_accuracy: 0.9659 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0748 - accuracy: 0.9782 - val_loss: 0.1424 - val_accuracy: 0.9674 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0741 - accuracy: 0.9788 - val_loss: 0.1487 - val_accuracy: 0.9665 - 85s/epoch - 64ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0726 - accuracy: 0.9789 - val_loss: 0.1429 - val_accuracy: 0.9665 - 85s/epoch - 64ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0697 - accuracy: 0.9802 - val_loss: 0.1442 - val_accuracy: 0.9682 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0646 - accuracy: 0.9815 - val_loss: 0.1357 - val_accuracy: 0.9703 - 85s/epoch - 65ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 - 85s - loss: 0.0635 - accuracy: 0.9815 - val_loss: 0.1345 - val_accuracy: 0.9697 - 85s/epoch - 65ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, BatchNormalization\n",
    "from keras.layers import Activation, Flatten, Dense, Dropout, ReLU\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from keras import layers, models\n",
    "import numpy as np\n",
    "from keras.layers import Activation\n",
    "\n",
    "class DFNet:\n",
    "    @staticmethod\n",
    "    def build(input_shape, classes, dropout_rate1=0.5, dropout_rate2=0.5, dropout_rate_fc=0.7):\n",
    "        model = Sequential()\n",
    "\n",
    "        # ... (previous model definition remains unchanged)\n",
    "        # Block 1\n",
    "        filter_num = [None,32, 64, 128, 256]\n",
    "        kernel_size = [None, 8, 8, 8, 8]\n",
    "        conv_stride_size = [None, 1, 1, 1, 1]\n",
    "        pool_stride_size = [None, 4, 4, 4, 4]\n",
    "        pool_size = [None, 8, 8, 8, 8]\n",
    "\n",
    "        for i in range(1, 4):\n",
    "            model.add(Conv1D(filters=filter_num[i], kernel_size=kernel_size[i],\n",
    "                             strides=conv_stride_size[i], padding='same',\n",
    "                             input_shape=input_shape if i == 1 else (None, input_shape[1]),\n",
    "                             name=f'block{i}_conv1'))\n",
    "            model.add(BatchNormalization(name=f'batch_normalization_{i * 2 - 1}'))\n",
    "            model.add(Activation('relu', name=f'block{i}_adv_act1'))\n",
    "            model.add(Conv1D(filters=filter_num[i], kernel_size=kernel_size[i],\n",
    "                             strides=conv_stride_size[i], padding='same',\n",
    "                             name=f'block{i}_conv2'))\n",
    "            model.add(BatchNormalization(name=f'batch_normalization_{i * 2}'))\n",
    "            model.add(Activation('relu', name=f'block{i}_adv_act2'))\n",
    "\n",
    "            model.add(MaxPooling1D(pool_size=pool_size[i], strides=pool_stride_size[i],\n",
    "                                   padding='same', name=f'block{i}_pool'))\n",
    "            model.add(Dropout(0.1, name=f'block{i}_dropout'))\n",
    "\n",
    "        # ... (rest of the model remains unchanged)\n",
    "\n",
    "        model.add(Flatten(name='flatten'))\n",
    "\n",
    "        # Fully connected layers\n",
    "        for i in range(1, 3):\n",
    "            model.add(Dense(512, kernel_initializer=glorot_uniform(seed=0), name=f'fc{i}'))\n",
    "            model.add(BatchNormalization(name=f'batch_normalization_{i + 8}'))\n",
    "            model.add(Activation('relu', name=f'fc{i}_act'))\n",
    "\n",
    "            # Experiment with different dropout rates\n",
    "            model.add(Dropout(dropout_rate_fc, name=f'fc{i}_dropout'))\n",
    "\n",
    "        # Output layer\n",
    "        model.add(Dense(classes, kernel_initializer=glorot_uniform(seed=0), name='fc_final'))\n",
    "        model.add(Activation('softmax', name=\"softmax\"))\n",
    "\n",
    "        print(\"Model built successfully.\")\n",
    "        return model\n",
    "    # Assuming input_shape and num_classes are defined as follows (adjust based on your actual data)\n",
    "input_shape = (5000, 1)\n",
    "num_classes = 96\n",
    "\n",
    "# Experiment with different dropout rates\n",
    "dropout_rate1 = 0.6\n",
    "dropout_rate2 = 0.5\n",
    "dropout_rate_fc = 0.4\n",
    "\n",
    "# Build the model with the specified dropout rates\n",
    "model = DFNet.build(input_shape=input_shape, classes=num_classes,\n",
    "                    dropout_rate1=dropout_rate1, dropout_rate2=dropout_rate2, dropout_rate_fc=dropout_rate_fc)\n",
    "\n",
    "\n",
    "# Print the model summary\n",
    "print(\"Model Summary:\")\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Assuming input_shape and num_classes are defined as follows (adjust based on your actual data)\n",
    "input_shape = (5000, 1)\n",
    "num_classes = 96\n",
    "\n",
    "# Experiment with different dropout rates\n",
    "dropout_rate1 = 0.6\n",
    "dropout_rate2 = 0.5\n",
    "dropout_rate_fc = 0.4\n",
    "\n",
    "# Load and merge data using the function you defined\n",
    "X_all, y_all = LoadDataNoDefOW_Training()\n",
    "# Define the number of folds\n",
    "n_splits = 5  # You can adjust this as needed\n",
    "\n",
    "# Initialize Stratified K-Fold\n",
    "stratkf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store results\n",
    "all_histories = []\n",
    "\n",
    "# Iterate over folds\n",
    "for fold, (train_index, test_index) in enumerate(stratkf.split(X_all, y_all)):\n",
    "    print(f\"\\nTraining on Fold {fold + 1}/{n_splits}\")\n",
    "\n",
    "    # Split the data\n",
    "    X_train, X_test = X_all[train_index], X_all[test_index]\n",
    "    y_train, y_test = y_all[train_index], y_all[test_index]\n",
    "    \n",
    "        # Build the model\n",
    "    model = DFNet.build(input_shape=input_shape, classes=num_classes,\n",
    "                        dropout_rate1=dropout_rate1, dropout_rate2=dropout_rate2, dropout_rate_fc=dropout_rate_fc)\n",
    "\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "     # Define early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "    # Train the model with early stopping\n",
    "    history = model.fit(X_train, y_train, epochs=25, batch_size=64, \n",
    "                        validation_data=(X_test, y_test), verbose=2, callbacks=[early_stopping])\n",
    "    \n",
    "   \n",
    "\n",
    "\n",
    "    # Train the model\n",
    "    #history = model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test), verbose=2)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
    "    print(f\"\\nFold {fold + 1} - Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    # Save history for later analysis if needed\n",
    "    all_histories.append(history)\n",
    "    # Check unique labels in y_train\n",
    "    \n",
    "    # Update num_classes based on the actual number of unique classes in your dataset\n",
    "#num_classes = len(np.unique(y_all))\n",
    "saved_path_keras = '/kaggle/working/DFNet_OpenWorld_NoDef.keras'\n",
    "model.save(saved_path_keras)\n",
    "\n",
    "print(\"Trained model saved successfully at:\", saved_path_keras)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983aec73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-07T14:22:58.889040Z",
     "iopub.status.busy": "2024-03-07T14:22:58.888578Z",
     "iopub.status.idle": "2024-03-07T14:23:08.462235Z",
     "shell.execute_reply": "2024-03-07T14:23:08.461266Z",
     "shell.execute_reply.started": "2024-03-07T14:22:58.889005Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "def LoadDataNoDefOW_Evaluation():\n",
    "\n",
    "    print(\"Loading non-defended dataset for open-world scenario for evaluation\")\n",
    "    # Point to the directory storing data\n",
    "    dataset_dir = '/kaggle/input/dataset-non-defended-open-world/'\n",
    "\n",
    "    # X represents a sequence of traffic directions\n",
    "    # y represents a sequence of corresponding label (website's label)\n",
    "    try:\n",
    "        # Load testing data\n",
    "        with open(dataset_dir + 'X_test_Mon_NoDef.pkl', 'rb') as handle:\n",
    "            X_test_Mon = np.array(pickle.load(handle, encoding='latin1'))\n",
    "        with open(dataset_dir + 'y_test_Mon_NoDef.pkl', 'rb') as handle:\n",
    "            y_test_Mon = np.array(pickle.load(handle, encoding='latin1'))\n",
    "        with open(dataset_dir + 'X_test_Unmon_NoDef.pkl', 'rb') as handle:\n",
    "            X_test_Unmon = np.array(pickle.load(handle, encoding='latin1'))\n",
    "        with open(dataset_dir + 'y_test_Unmon_NoDef.pkl', 'rb') as handle:\n",
    "            y_test_Unmon = np.array(pickle.load(handle, encoding='latin1'))\n",
    "\n",
    "        X_test_Mon = np.array(X_test_Mon)\n",
    "        y_test_Mon = np.array(y_test_Mon)\n",
    "        X_test_Unmon = np.array(X_test_Unmon)\n",
    "        y_test_Unmon = np.array(y_test_Unmon)\n",
    "\n",
    "        return X_test_Mon, y_test_Mon, X_test_Unmon, y_test_Unmon\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", str(e))\n",
    "        return None\n",
    "\n",
    "# Call the function to load evaluation data\n",
    "LoadDataNoDefOW_Evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcc9788",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-07T14:23:11.716495Z",
     "iopub.status.busy": "2024-03-07T14:23:11.716132Z",
     "iopub.status.idle": "2024-03-07T14:26:21.411625Z",
     "shell.execute_reply": "2024-03-07T14:26:21.410519Z",
     "shell.execute_reply.started": "2024-03-07T14:23:11.716464Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "def Prediction(trained_model = None, dataset = None):\n",
    "    X_test_Mon = dataset['X_test_Mon'].astype('float32')\n",
    "    X_test_Unmon = dataset['X_test_Unmon'].astype('float32')\n",
    "    print (\"Total testing data \", len(X_test_Mon) + len(X_test_Unmon))\n",
    "    X_test_Mon = X_test_Mon[:, :, np.newaxis]\n",
    "    X_test_Unmon = X_test_Unmon[:, :, np.newaxis]\n",
    "    result_Mon = trained_model.predict(X_test_Mon, verbose=2)\n",
    "    result_Unmon = trained_model.predict(X_test_Unmon, verbose=2)\n",
    "    return result_Mon, result_Unmon\n",
    "def Evaluation(threshold_val = None, monitored_label = None,\n",
    "                   unmonitored_label = None, result_Mon = None,\n",
    "                   result_Unmon = None, log_file = None):\n",
    "    print (\"Testing with threshold = \", threshold_val)\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    # ==============================================================\n",
    "    # Test with Monitored testing instances\n",
    "    # evaluation\n",
    "    for i in range(len(result_Mon)):\n",
    "        sm_vector = result_Mon[i]\n",
    "        predicted_class = np.argmax(sm_vector)\n",
    "        max_prob = max(sm_vector)\n",
    "\n",
    "        if predicted_class in monitored_label: # predicted as Monitored\n",
    "            if max_prob >= threshold_val: # predicted as Monitored and actual site is Monitored\n",
    "                TP = TP + 1\n",
    "            else: # predicted as Unmonitored and actual site is Monitored\n",
    "                FN = FN + 1\n",
    "        elif predicted_class in unmonitored_label: # predicted as Unmonitored and actual site is Monitored\n",
    "            FN = FN + 1\n",
    "\n",
    "    # ==============================================================\n",
    "    # Test with Unmonitored testing instances\n",
    "    # evaluation\n",
    "    for i in range(len(result_Unmon)):\n",
    "        sm_vector = result_Unmon[i]\n",
    "        predicted_class = np.argmax(sm_vector)\n",
    "        max_prob = max(sm_vector)\n",
    "\n",
    "        if predicted_class in monitored_label: # predicted as Monitored\n",
    "            if max_prob >= threshold_val: # predicted as Monitored and actual site is Unmonitored\n",
    "                FP = FP + 1\n",
    "            else: # predicted as Unmonitored and actual site is Unmonitored\n",
    "                TN = TN + 1\n",
    "        elif predicted_class in unmonitored_label: # predicted as Unmonitored and actual site is Unmonitored\n",
    "            TN = TN + 1\n",
    "            \n",
    "    print (\"TP : \", TP)\n",
    "    print (\"FP : \", FP)\n",
    "    print (\"TN : \", TN)\n",
    "    print (\"FN : \", FN)\n",
    "    print (\"Total  : \", TP + FP + TN + FN)\n",
    "    TPR = float(TP) / (TP + FN)\n",
    "    print (\"TPR : \", TPR)\n",
    "    FPR = float(FP) / (FP + TN)\n",
    "    print (\"FPR : \",  FPR)\n",
    "    Precision = float(TP) / (TP + FP)\n",
    "    print (\"Precision : \", Precision)\n",
    "    Recall = float(TP) / (TP + FN)\n",
    "    print (\"Recall : \", Recall)\n",
    "    print (\"\\n\")\n",
    "    log_file.writelines(\"%.6f,%d,%d,%d,%d,%.6f,%.6f,%.6f,%.6f\\n\"%(threshold_val, TP, FP, TN, FN, TPR, FPR, Precision, Recall))\n",
    "\n",
    "# The evaluation of Open World scenario\n",
    "def OW_Evaluation():\n",
    "    evaluation_type = 'OpenWorld_NoDef'\n",
    "    print(\"Evaluation type: \", evaluation_type)\n",
    "\n",
    "    # Create the 'results' directory if it doesn't exist\n",
    "    results_dir = '../results/'\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "    threshold = 1.0 - 1 / np.logspace(0.05, 2, num=15, endpoint=True)\n",
    "    file_name = f'{results_dir}{evaluation_type}.csv'\n",
    "    log_file = open(file_name, \"w\")  # Open the file in text mode, not binary mode\n",
    "    # Load data\n",
    "    dataset = {}\n",
    "    model_name = ''\n",
    "    print (\"Loading data ...\")\n",
    "    #from utility import LoadDataNoDefOW_Evaluation\n",
    "    X_test_Mon, y_test_Mon, X_test_Unmon, y_test_Unmon = LoadDataNoDefOW_Evaluation()\n",
    "    # Load pre-trained model saved from 'Open_World_DF_***_Training.py'\n",
    "    #model_name = '/kaggle/working/DFNet_OpenWorld_NoDef.keras'\n",
    "    model_name = '/kaggle/working/DFNet_OpenWorld_NoDef.keras'\n",
    "\n",
    "\n",
    "    dataset['X_test_Mon'] = X_test_Mon\n",
    "    dataset['y_test_Mon'] = y_test_Mon\n",
    "    dataset['X_test_Unmon'] = X_test_Unmon\n",
    "    dataset['y_test_Unmon'] = y_test_Unmon\n",
    "\n",
    "    print (\"Data loaded!\")\n",
    "    print (\"Loading DF model ...\")\n",
    "    print (\"The log file will be saved at \", file_name)\n",
    "    print (\"-- The log file will contains\")\n",
    "    print (\"-- TP, FP, TN, FN, TPR, FPR, Precision, and Recall for each different threshold\")\n",
    "    print (\"-- These results will be used to plot the ROC or Precision&Recall Graph\")\n",
    "    trained_model = load_model(model_name)\n",
    "    print (\"Model loaded!\")\n",
    "    print (\"Evaluation Type: \", evaluation_type)\n",
    "    print (\"Use the model from \", model_name)\n",
    "    result_Mon, result_Unmon = Prediction(trained_model = trained_model, dataset = dataset)\n",
    "    monitored_label = list(y_test_Mon)\n",
    "    unmonitored_label = list(y_test_Unmon)\n",
    "    log_file.writelines(\"%s,%s,%s,%s,%s,%s  ,%s  ,  %s, %s\\n\" % ('Threshold', 'TP', 'FP', 'TN', 'FN', 'TPR', 'FPR', 'Precision', 'Recall'))\n",
    "    for th in threshold:\n",
    "        Evaluation(threshold_val = th, monitored_label = monitored_label,\n",
    "                   unmonitored_label = unmonitored_label, result_Mon = result_Mon,\n",
    "                   result_Unmon = result_Unmon, log_file = log_file)\n",
    "    log_file.close()  \n",
    "\n",
    "OW_Evaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017f065c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "ReLU besst approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878dd6d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-07T02:09:07.206304Z",
     "iopub.status.busy": "2024-03-07T02:09:07.205981Z",
     "iopub.status.idle": "2024-03-07T04:34:38.963035Z",
     "shell.execute_reply": "2024-03-07T04:34:38.961989Z",
     "shell.execute_reply.started": "2024-03-07T02:09:07.206276Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, BatchNormalization\n",
    "from keras.layers import Activation, Flatten, Dense, Dropout, ReLU\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from keras import layers, models\n",
    "import numpy as np\n",
    "from keras.layers import Activation\n",
    "\n",
    "class DFNet:\n",
    "    @staticmethod\n",
    "    def build(input_shape, classes, dropout_rate1=0.5, dropout_rate2=0.5, dropout_rate_fc=0.7):\n",
    "        model = Sequential()\n",
    "\n",
    "        # ... (previous model definition remains unchanged)\n",
    "        # Block 1\n",
    "        filter_num = [None,32, 64, 128, 256]\n",
    "        kernel_size = [None, 8, 8, 8, 8]\n",
    "        conv_stride_size = [None, 1, 1, 1, 1]\n",
    "        pool_stride_size = [None, 4, 4, 4, 4]\n",
    "        pool_size = [None, 8, 8, 8, 8]\n",
    "\n",
    "        for i in range(1, 4):\n",
    "            model.add(Conv1D(filters=filter_num[i], kernel_size=kernel_size[i],\n",
    "                             strides=conv_stride_size[i], padding='same',\n",
    "                             input_shape=input_shape if i == 1 else (None, input_shape[1]),\n",
    "                             name=f'block{i}_conv1'))\n",
    "            model.add(BatchNormalization(name=f'batch_normalization_{i * 2 - 1}'))\n",
    "            model.add(Activation('relu', name=f'block{i}_adv_act1'))\n",
    "            model.add(Conv1D(filters=filter_num[i], kernel_size=kernel_size[i],\n",
    "                             strides=conv_stride_size[i], padding='same',\n",
    "                             name=f'block{i}_conv2'))\n",
    "            model.add(BatchNormalization(name=f'batch_normalization_{i * 2}'))\n",
    "            model.add(Activation('relu', name=f'block{i}_adv_act2'))\n",
    "\n",
    "            model.add(MaxPooling1D(pool_size=pool_size[i], strides=pool_stride_size[i],\n",
    "                                   padding='same', name=f'block{i}_pool'))\n",
    "            model.add(Dropout(0.1, name=f'block{i}_dropout'))\n",
    "\n",
    "        # ... (rest of the model remains unchanged)\n",
    "\n",
    "        model.add(Flatten(name='flatten'))\n",
    "\n",
    "        # Fully connected layers\n",
    "        for i in range(1, 3):\n",
    "            model.add(Dense(512, kernel_initializer=glorot_uniform(seed=0), name=f'fc{i}'))\n",
    "            model.add(BatchNormalization(name=f'batch_normalization_{i + 8}'))\n",
    "            model.add(Activation('relu', name=f'fc{i}_act'))\n",
    "\n",
    "            # Experiment with different dropout rates\n",
    "            model.add(Dropout(dropout_rate_fc, name=f'fc{i}_dropout'))\n",
    "\n",
    "        # Output layer\n",
    "        model.add(Dense(classes, kernel_initializer=glorot_uniform(seed=0), name='fc_final'))\n",
    "        model.add(Activation('softmax', name=\"softmax\"))\n",
    "\n",
    "        print(\"Model built successfully.\")\n",
    "        return model\n",
    "    # Assuming input_shape and num_classes are defined as follows (adjust based on your actual data)\n",
    "input_shape = (5000, 1)\n",
    "num_classes = 96\n",
    "\n",
    "# Experiment with different dropout rates\n",
    "dropout_rate1 = 0.6\n",
    "dropout_rate2 = 0.5\n",
    "dropout_rate_fc = 0.4\n",
    "\n",
    "# Build the model with the specified dropout rates\n",
    "model = DFNet.build(input_shape=input_shape, classes=num_classes,\n",
    "                    dropout_rate1=dropout_rate1, dropout_rate2=dropout_rate2, dropout_rate_fc=dropout_rate_fc)\n",
    "\n",
    "\n",
    "# Print the model summary\n",
    "print(\"Model Summary:\")\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Assuming input_shape and num_classes are defined as follows (adjust based on your actual data)\n",
    "input_shape = (5000, 1)\n",
    "num_classes = 96\n",
    "\n",
    "# Experiment with different dropout rates\n",
    "dropout_rate1 = 0.6\n",
    "dropout_rate2 = 0.5\n",
    "dropout_rate_fc = 0.4\n",
    "\n",
    "# Load and merge data using the function you defined\n",
    "X_all, y_all = LoadDataNoDefOW_Training()\n",
    "# Define the number of folds\n",
    "n_splits = 5  # You can adjust this as needed\n",
    "\n",
    "# Initialize Stratified K-Fold\n",
    "stratkf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store results\n",
    "all_histories = []\n",
    "\n",
    "# Iterate over folds\n",
    "for fold, (train_index, test_index) in enumerate(stratkf.split(X_all, y_all)):\n",
    "    print(f\"\\nTraining on Fold {fold + 1}/{n_splits}\")\n",
    "\n",
    "    # Split the data\n",
    "    X_train, X_test = X_all[train_index], X_all[test_index]\n",
    "    y_train, y_test = y_all[train_index], y_all[test_index]\n",
    "    \n",
    "        # Build the model\n",
    "    model = DFNet.build(input_shape=input_shape, classes=num_classes,\n",
    "                        dropout_rate1=dropout_rate1, dropout_rate2=dropout_rate2, dropout_rate_fc=dropout_rate_fc)\n",
    "\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "     # Define early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    # Train the model with early stopping\n",
    "    history = model.fit(X_train, y_train, epochs=20, batch_size=64, \n",
    "                        validation_data=(X_test, y_test), verbose=2, callbacks=[early_stopping])\n",
    "    \n",
    "   \n",
    "\n",
    "\n",
    "    # Train the model\n",
    "    #history = model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test), verbose=2)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
    "    print(f\"\\nFold {fold + 1} - Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    # Save history for later analysis if needed\n",
    "    all_histories.append(history)\n",
    "    # Check unique labels in y_train\n",
    "    \n",
    "    # Update num_classes based on the actual number of unique classes in your dataset\n",
    "#num_classes = len(np.unique(y_all))\n",
    "saved_path_keras = '/kaggle/working/DFNet_OpenWorld_NoDef.keras'\n",
    "model.save(saved_path_keras)\n",
    "\n",
    "print(\"Trained model saved successfully at:\", saved_path_keras)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd0f135",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-07T04:39:38.717429Z",
     "iopub.status.busy": "2024-03-07T04:39:38.716495Z",
     "iopub.status.idle": "2024-03-07T04:39:46.367439Z",
     "shell.execute_reply": "2024-03-07T04:39:46.366491Z",
     "shell.execute_reply.started": "2024-03-07T04:39:38.717393Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data for non-defended dataset for OW evaluation\n",
    "import pickle\n",
    "import numpy as np\n",
    "def LoadDataNoDefOW_Evaluation():\n",
    "\n",
    "    print(\"Loading non-defended dataset for open-world scenario for evaluation\")\n",
    "    # Point to the directory storing data\n",
    "    dataset_dir = '/kaggle/input/dataset-non-defended-open-world/'\n",
    "\n",
    "    # X represents a sequence of traffic directions\n",
    "    # y represents a sequence of corresponding label (website's label)\n",
    "    try:\n",
    "        # Load testing data\n",
    "        with open(dataset_dir + 'X_test_Mon_NoDef.pkl', 'rb') as handle:\n",
    "            X_test_Mon = np.array(pickle.load(handle, encoding='latin1'))\n",
    "        with open(dataset_dir + 'y_test_Mon_NoDef.pkl', 'rb') as handle:\n",
    "            y_test_Mon = np.array(pickle.load(handle, encoding='latin1'))\n",
    "        with open(dataset_dir + 'X_test_Unmon_NoDef.pkl', 'rb') as handle:\n",
    "            X_test_Unmon = np.array(pickle.load(handle, encoding='latin1'))\n",
    "        with open(dataset_dir + 'y_test_Unmon_NoDef.pkl', 'rb') as handle:\n",
    "            y_test_Unmon = np.array(pickle.load(handle, encoding='latin1'))\n",
    "\n",
    "        X_test_Mon = np.array(X_test_Mon)\n",
    "        y_test_Mon = np.array(y_test_Mon)\n",
    "        X_test_Unmon = np.array(X_test_Unmon)\n",
    "        y_test_Unmon = np.array(y_test_Unmon)\n",
    "\n",
    "        return X_test_Mon, y_test_Mon, X_test_Unmon, y_test_Unmon\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", str(e))\n",
    "        return None\n",
    "\n",
    "# Call the function to load evaluation data\n",
    "LoadDataNoDefOW_Evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2e054e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-07T04:39:46.369504Z",
     "iopub.status.busy": "2024-03-07T04:39:46.369188Z",
     "iopub.status.idle": "2024-03-07T04:42:52.848685Z",
     "shell.execute_reply": "2024-03-07T04:42:52.847527Z",
     "shell.execute_reply.started": "2024-03-07T04:39:46.369477Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "def Prediction(trained_model = None, dataset = None):\n",
    "    X_test_Mon = dataset['X_test_Mon'].astype('float32')\n",
    "    X_test_Unmon = dataset['X_test_Unmon'].astype('float32')\n",
    "    print (\"Total testing data \", len(X_test_Mon) + len(X_test_Unmon))\n",
    "    X_test_Mon = X_test_Mon[:, :, np.newaxis]\n",
    "    X_test_Unmon = X_test_Unmon[:, :, np.newaxis]\n",
    "    result_Mon = trained_model.predict(X_test_Mon, verbose=2)\n",
    "    result_Unmon = trained_model.predict(X_test_Unmon, verbose=2)\n",
    "    return result_Mon, result_Unmon\n",
    "def Evaluation(threshold_val = None, monitored_label = None,\n",
    "                   unmonitored_label = None, result_Mon = None,\n",
    "                   result_Unmon = None, log_file = None):\n",
    "    print (\"Testing with threshold = \", threshold_val)\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    # ==============================================================\n",
    "    # Test with Monitored testing instances\n",
    "    # evaluation\n",
    "    for i in range(len(result_Mon)):\n",
    "        sm_vector = result_Mon[i]\n",
    "        predicted_class = np.argmax(sm_vector)\n",
    "        max_prob = max(sm_vector)\n",
    "\n",
    "        if predicted_class in monitored_label: # predicted as Monitored\n",
    "            if max_prob >= threshold_val: # predicted as Monitored and actual site is Monitored\n",
    "                TP = TP + 1\n",
    "            else: # predicted as Unmonitored and actual site is Monitored\n",
    "                FN = FN + 1\n",
    "        elif predicted_class in unmonitored_label: # predicted as Unmonitored and actual site is Monitored\n",
    "            FN = FN + 1\n",
    "\n",
    "    # ==============================================================\n",
    "    # Test with Unmonitored testing instances\n",
    "    # evaluation\n",
    "    for i in range(len(result_Unmon)):\n",
    "        sm_vector = result_Unmon[i]\n",
    "        predicted_class = np.argmax(sm_vector)\n",
    "        max_prob = max(sm_vector)\n",
    "\n",
    "        if predicted_class in monitored_label: # predicted as Monitored\n",
    "            if max_prob >= threshold_val: # predicted as Monitored and actual site is Unmonitored\n",
    "                FP = FP + 1\n",
    "            else: # predicted as Unmonitored and actual site is Unmonitored\n",
    "                TN = TN + 1\n",
    "        elif predicted_class in unmonitored_label: # predicted as Unmonitored and actual site is Unmonitored\n",
    "            TN = TN + 1\n",
    "            \n",
    "    print (\"TP : \", TP)\n",
    "    print (\"FP : \", FP)\n",
    "    print (\"TN : \", TN)\n",
    "    print (\"FN : \", FN)\n",
    "    print (\"Total  : \", TP + FP + TN + FN)\n",
    "    TPR = float(TP) / (TP + FN)\n",
    "    print (\"TPR : \", TPR)\n",
    "    FPR = float(FP) / (FP + TN)\n",
    "    print (\"FPR : \",  FPR)\n",
    "    Precision = float(TP) / (TP + FP)\n",
    "    print (\"Precision : \", Precision)\n",
    "    Recall = float(TP) / (TP + FN)\n",
    "    print (\"Recall : \", Recall)\n",
    "    print (\"\\n\")\n",
    "    log_file.writelines(\"%.6f,%d,%d,%d,%d,%.6f,%.6f,%.6f,%.6f\\n\"%(threshold_val, TP, FP, TN, FN, TPR, FPR, Precision, Recall))\n",
    "\n",
    "# The evaluation of Open World scenario\n",
    "def OW_Evaluation():\n",
    "    evaluation_type = 'OpenWorld_NoDef'\n",
    "    print(\"Evaluation type: \", evaluation_type)\n",
    "\n",
    "    # Create the 'results' directory if it doesn't exist\n",
    "    results_dir = '../results/'\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "    threshold = 1.0 - 1 / np.logspace(0.05, 2, num=15, endpoint=True)\n",
    "    file_name = f'{results_dir}{evaluation_type}.csv'\n",
    "    log_file = open(file_name, \"w\")  # Open the file in text mode, not binary mode\n",
    "    # Load data\n",
    "    dataset = {}\n",
    "    model_name = ''\n",
    "    print (\"Loading data ...\")\n",
    "    #from utility import LoadDataNoDefOW_Evaluation\n",
    "    X_test_Mon, y_test_Mon, X_test_Unmon, y_test_Unmon = LoadDataNoDefOW_Evaluation()\n",
    "    # Load pre-trained model saved from 'Open_World_DF_***_Training.py'\n",
    "    #model_name = '/kaggle/working/DFNet_OpenWorld_NoDef.keras'\n",
    "    model_name = '/kaggle/working/DFNet_OpenWorld_NoDef.keras'\n",
    "\n",
    "\n",
    "    dataset['X_test_Mon'] = X_test_Mon\n",
    "    dataset['y_test_Mon'] = y_test_Mon\n",
    "    dataset['X_test_Unmon'] = X_test_Unmon\n",
    "    dataset['y_test_Unmon'] = y_test_Unmon\n",
    "\n",
    "    print (\"Data loaded!\")\n",
    "    print (\"Loading DF model ...\")\n",
    "    print (\"The log file will be saved at \", file_name)\n",
    "    print (\"-- The log file will contains\")\n",
    "    print (\"-- TP, FP, TN, FN, TPR, FPR, Precision, and Recall for each different threshold\")\n",
    "    print (\"-- These results will be used to plot the ROC or Precision&Recall Graph\")\n",
    "    trained_model = load_model(model_name)\n",
    "    print (\"Model loaded!\")\n",
    "    print (\"Evaluation Type: \", evaluation_type)\n",
    "    print (\"Use the model from \", model_name)\n",
    "    result_Mon, result_Unmon = Prediction(trained_model = trained_model, dataset = dataset)\n",
    "    monitored_label = list(y_test_Mon)\n",
    "    unmonitored_label = list(y_test_Unmon)\n",
    "    log_file.writelines(\"%s,%s,%s,%s,%s,%s  ,%s  ,  %s, %s\\n\" % ('Threshold', 'TP', 'FP', 'TN', 'FN', 'TPR', 'FPR', 'Precision', 'Recall'))\n",
    "    for th in threshold:\n",
    "        Evaluation(threshold_val = th, monitored_label = monitored_label,\n",
    "                   unmonitored_label = unmonitored_label, result_Mon = result_Mon,\n",
    "                   result_Unmon = result_Unmon, log_file = log_file)\n",
    "    log_file.close()  \n",
    "\n",
    "OW_Evaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aec545a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "//practice with Relu//.7/.5/.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec6cd0d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "best approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1539e27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-07T07:12:40.316106Z",
     "iopub.status.busy": "2024-03-07T07:12:40.315708Z",
     "iopub.status.idle": "2024-03-07T07:13:25.324373Z",
     "shell.execute_reply": "2024-03-07T07:13:25.323208Z",
     "shell.execute_reply.started": "2024-03-07T07:12:40.316074Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import numpy as np  # Add this line\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, BatchNormalization\n",
    "from keras.layers import Activation, Flatten, Dense, Dropout, ReLU\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from keras import layers, models\n",
    "\n",
    "# Load data for non-defended dataset for OW training\n",
    "def LoadDataNoDefOW_Training():\n",
    "\n",
    "    print(\"Loading non-defended dataset for open-world scenario for training\")\n",
    "    # Point to the directory storing data\n",
    "    dataset_dir = '/kaggle/input/dataset-non-defended-open-world/'\n",
    "\n",
    "    # X represents a sequence of traffic directions\n",
    "    # y represents a sequence of corresponding label (website's label)\n",
    "\n",
    "    try:\n",
    "        # Load training data\n",
    "        with open(dataset_dir + 'X_train_NoDef.pkl', 'rb') as handle:\n",
    "            X_train = np.array(pickle.load(handle, encoding='latin1'))\n",
    "        print(\"X_train loaded\")\n",
    "        with open(dataset_dir + 'y_train_NoDef.pkl', 'rb') as handle:\n",
    "            y_train = np.array(pickle.load(handle, encoding='latin1'))\n",
    "        print(\"y_train loaded\")\n",
    "\n",
    "        # Load validation data\n",
    "        with open(dataset_dir + 'X_valid_NoDef.pkl', 'rb') as handle:\n",
    "            X_valid = np.array(pickle.load(handle, encoding='latin1'))\n",
    "        print(\"X_valid loaded\")\n",
    "        with open(dataset_dir + 'y_valid_NoDef.pkl', 'rb') as handle:\n",
    "            y_valid = np.array(pickle.load(handle, encoding='latin1'))\n",
    "        print(\"y_valid loaded\")\n",
    "\n",
    "        print(\"Data dimensions:\")\n",
    "        print(\"X: Training data's shape : \", X_train.shape)\n",
    "        print(\"y: Training data's shape : \", y_train.shape)\n",
    "        print(\"X: Validation data's shape : \", X_valid.shape)\n",
    "        print(\"y: Validation data's shape : \", y_valid.shape)\n",
    "        \n",
    "        print(\"Any None values in X_train:\", np.any(np.isnan(X_train)))\n",
    "        print(\"Any None values in y_train:\", np.any(np.isnan(y_train)))\n",
    "        print(\"Any None values in X_valid:\", np.any(np.isnan(X_valid)))\n",
    "        print(\"Any None values in y_valid:\", np.any(np.isnan(y_valid)))\n",
    "        \n",
    "        # Merge datasets\n",
    "        X_all = np.concatenate((X_train, X_valid), axis=0)\n",
    "        y_all = np.concatenate((y_train, y_valid), axis=0)\n",
    "\n",
    "        print(\"Merged data dimensions:\")\n",
    "        print(\"X: Merged data's shape : \", X_all.shape)\n",
    "        print(\"y: Merged data's shape : \", y_all.shape)\n",
    "        \n",
    "        # Print features of the merged dataset\n",
    "        print(\"Features of the merged dataset:\")\n",
    "        print(X_all)\n",
    "         # Print features of the merged dataset\n",
    "        print(\"Features of the merged dataset:\")\n",
    "        print(y_all)\n",
    "        \n",
    "       \n",
    "        return X_all, y_all\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", str(e))\n",
    "        return None\n",
    "\n",
    "# Call the function to load, merge, and balance data\n",
    "X_all, y_all = LoadDataNoDefOW_Training()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81ca61a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-07T07:13:25.327793Z",
     "iopub.status.busy": "2024-03-07T07:13:25.326861Z",
     "iopub.status.idle": "2024-03-07T07:13:31.605518Z",
     "shell.execute_reply": "2024-03-07T07:13:31.604526Z",
     "shell.execute_reply.started": "2024-03-07T07:13:25.327752Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import numpy as np  # Add this line\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, BatchNormalization\n",
    "from keras.layers import Activation, Flatten, Dense, Dropout, ELU\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from keras import layers, models\n",
    "\n",
    "# Load data for non-defended dataset for OW training\n",
    "def LoadDataNoDefOW_Training():\n",
    "\n",
    "    print(\"Loading non-defended dataset for open-world scenario for training\")\n",
    "    # Point to the directory storing data\n",
    "    dataset_dir = '/kaggle/input/dataset-non-defended-open-world/'\n",
    "\n",
    "    # X represents a sequence of traffic directions\n",
    "    # y represents a sequence of corresponding label (website's label)\n",
    "\n",
    "    try:\n",
    "        # Load training data\n",
    "        with open(dataset_dir + 'X_train_NoDef.pkl', 'rb') as handle:\n",
    "            X_train = np.array(pickle.load(handle, encoding='latin1'))\n",
    "        print(\"X_train loaded\")\n",
    "        with open(dataset_dir + 'y_train_NoDef.pkl', 'rb') as handle:\n",
    "            y_train = np.array(pickle.load(handle, encoding='latin1'))\n",
    "        print(\"y_train loaded\")\n",
    "\n",
    "        # Load validation data\n",
    "        with open(dataset_dir + 'X_valid_NoDef.pkl', 'rb') as handle:\n",
    "            X_valid = np.array(pickle.load(handle, encoding='latin1'))\n",
    "        print(\"X_valid loaded\")\n",
    "        with open(dataset_dir + 'y_valid_NoDef.pkl', 'rb') as handle:\n",
    "            y_valid = np.array(pickle.load(handle, encoding='latin1'))\n",
    "        print(\"y_valid loaded\")\n",
    "\n",
    "        print(\"Data dimensions:\")\n",
    "        print(\"X: Training data's shape : \", X_train.shape)\n",
    "        print(\"y: Training data's shape : \", y_train.shape)\n",
    "        print(\"X: Validation data's shape : \", X_valid.shape)\n",
    "        print(\"y: Validation data's shape : \", y_valid.shape)\n",
    "        \n",
    "        print(\"Any None values in X_train:\", np.any(np.isnan(X_train)))\n",
    "        print(\"Any None values in y_train:\", np.any(np.isnan(y_train)))\n",
    "        print(\"Any None values in X_valid:\", np.any(np.isnan(X_valid)))\n",
    "        print(\"Any None values in y_valid:\", np.any(np.isnan(y_valid)))\n",
    "        \n",
    "        # Merge datasets\n",
    "        X_all = np.concatenate((X_train, X_valid), axis=0)\n",
    "        y_all = np.concatenate((y_train, y_valid), axis=0)\n",
    "\n",
    "        print(\"Merged data dimensions:\")\n",
    "        print(\"X: Merged data's shape : \", X_all.shape)\n",
    "        print(\"y: Merged data's shape : \", y_all.shape)\n",
    "        \n",
    "        # Print features of the merged dataset\n",
    "        print(\"Features of the merged dataset:\")\n",
    "        print(X_all)\n",
    "         # Print features of the merged dataset\n",
    "        print(\"Features of the merged dataset:\")\n",
    "        print(y_all)\n",
    "        \n",
    "       \n",
    "        return X_all, y_all\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", str(e))\n",
    "        return None\n",
    "\n",
    "# Call the function to load, merge, and balance data\n",
    "X_all, y_all = LoadDataNoDefOW_Training()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c408098",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-07T07:13:31.607415Z",
     "iopub.status.busy": "2024-03-07T07:13:31.607024Z",
     "iopub.status.idle": "2024-03-07T09:42:13.208742Z",
     "shell.execute_reply": "2024-03-07T09:42:13.207695Z",
     "shell.execute_reply.started": "2024-03-07T07:13:31.607378Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, BatchNormalization\n",
    "from keras.layers import Activation, Flatten, Dense, Dropout, ReLU\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from keras import layers, models\n",
    "import numpy as np\n",
    "from keras.layers import Activation\n",
    "\n",
    "class DFNet:\n",
    "    @staticmethod\n",
    "    def build(input_shape, classes, dropout_rate1=0.5, dropout_rate2=0.5, dropout_rate_fc=0.7):\n",
    "        model = Sequential()\n",
    "\n",
    "        # ... (previous model definition remains unchanged)\n",
    "        # Block 1\n",
    "        filter_num = [None,32, 64, 128, 256]\n",
    "        kernel_size = [None, 8, 8, 8, 8]\n",
    "        conv_stride_size = [None, 1, 1, 1, 1]\n",
    "        pool_stride_size = [None, 4, 4, 4, 4]\n",
    "        pool_size = [None, 8, 8, 8, 8]\n",
    "\n",
    "        for i in range(1, 4):\n",
    "            model.add(Conv1D(filters=filter_num[i], kernel_size=kernel_size[i],\n",
    "                             strides=conv_stride_size[i], padding='same',\n",
    "                             input_shape=input_shape if i == 1 else (None, input_shape[1]),\n",
    "                             name=f'block{i}_conv1'))\n",
    "            model.add(BatchNormalization(name=f'batch_normalization_{i * 2 - 1}'))\n",
    "            model.add(Activation('relu', name=f'block{i}_adv_act1'))\n",
    "            model.add(Conv1D(filters=filter_num[i], kernel_size=kernel_size[i],\n",
    "                             strides=conv_stride_size[i], padding='same',\n",
    "                             name=f'block{i}_conv2'))\n",
    "            model.add(BatchNormalization(name=f'batch_normalization_{i * 2}'))\n",
    "            model.add(Activation('relu', name=f'block{i}_adv_act2'))\n",
    "\n",
    "            model.add(MaxPooling1D(pool_size=pool_size[i], strides=pool_stride_size[i],\n",
    "                                   padding='same', name=f'block{i}_pool'))\n",
    "            model.add(Dropout(0.1, name=f'block{i}_dropout'))\n",
    "\n",
    "        # ... (rest of the model remains unchanged)\n",
    "\n",
    "        model.add(Flatten(name='flatten'))\n",
    "\n",
    "        # Fully connected layers\n",
    "        for i in range(1, 3):\n",
    "            model.add(Dense(512, kernel_initializer=glorot_uniform(seed=0), name=f'fc{i}'))\n",
    "            model.add(BatchNormalization(name=f'batch_normalization_{i + 8}'))\n",
    "            model.add(Activation('relu', name=f'fc{i}_act'))\n",
    "\n",
    "            # Experiment with different dropout rates\n",
    "            model.add(Dropout(dropout_rate_fc, name=f'fc{i}_dropout'))\n",
    "\n",
    "        # Output layer\n",
    "        model.add(Dense(classes, kernel_initializer=glorot_uniform(seed=0), name='fc_final'))\n",
    "        model.add(Activation('softmax', name=\"softmax\"))\n",
    "\n",
    "        print(\"Model built successfully.\")\n",
    "        return model\n",
    "    # Assuming input_shape and num_classes are defined as follows (adjust based on your actual data)\n",
    "input_shape = (5000, 1)\n",
    "num_classes = 96\n",
    "\n",
    "# Experiment with different dropout rates\n",
    "dropout_rate1 = 0.6\n",
    "dropout_rate2 = 0.5\n",
    "dropout_rate_fc = 0.4\n",
    "\n",
    "# Build the model with the specified dropout rates\n",
    "model = DFNet.build(input_shape=input_shape, classes=num_classes,\n",
    "                    dropout_rate1=dropout_rate1, dropout_rate2=dropout_rate2, dropout_rate_fc=dropout_rate_fc)\n",
    "\n",
    "\n",
    "# Print the model summary\n",
    "print(\"Model Summary:\")\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Assuming input_shape and num_classes are defined as follows (adjust based on your actual data)\n",
    "input_shape = (5000, 1)\n",
    "num_classes = 96\n",
    "\n",
    "# Experiment with different dropout rates\n",
    "dropout_rate1 = 0.6\n",
    "dropout_rate2 = 0.5\n",
    "dropout_rate_fc = 0.4\n",
    "\n",
    "# Load and merge data using the function you defined\n",
    "X_all, y_all = LoadDataNoDefOW_Training()\n",
    "# Define the number of folds\n",
    "n_splits = 5  # You can adjust this as needed\n",
    "\n",
    "# Initialize Stratified K-Fold\n",
    "stratkf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store results\n",
    "all_histories = []\n",
    "\n",
    "# Iterate over folds\n",
    "for fold, (train_index, test_index) in enumerate(stratkf.split(X_all, y_all)):\n",
    "    print(f\"\\nTraining on Fold {fold + 1}/{n_splits}\")\n",
    "\n",
    "    # Split the data\n",
    "    X_train, X_test = X_all[train_index], X_all[test_index]\n",
    "    y_train, y_test = y_all[train_index], y_all[test_index]\n",
    "    \n",
    "        # Build the model\n",
    "    model = DFNet.build(input_shape=input_shape, classes=num_classes,\n",
    "                        dropout_rate1=dropout_rate1, dropout_rate2=dropout_rate2, dropout_rate_fc=dropout_rate_fc)\n",
    "\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "     # Define early stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    # Train the model with early stopping\n",
    "    history = model.fit(X_train, y_train, epochs=20, batch_size=64, \n",
    "                        validation_data=(X_test, y_test), verbose=2, callbacks=[early_stopping])\n",
    "    \n",
    "   \n",
    "\n",
    "\n",
    "    # Train the model\n",
    "    #history = model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test), verbose=2)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
    "    print(f\"\\nFold {fold + 1} - Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    # Save history for later analysis if needed\n",
    "    all_histories.append(history)\n",
    "    # Check unique labels in y_train\n",
    "    \n",
    "    # Update num_classes based on the actual number of unique classes in your dataset\n",
    "#num_classes = len(np.unique(y_all))\n",
    "saved_path_keras = '/kaggle/working/DFNet_OpenWorld_NoDef.keras'\n",
    "model.save(saved_path_keras)\n",
    "\n",
    "print(\"Trained model saved successfully at:\", saved_path_keras)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c68e00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-07T09:57:43.680486Z",
     "iopub.status.busy": "2024-03-07T09:57:43.680111Z",
     "iopub.status.idle": "2024-03-07T09:57:51.410716Z",
     "shell.execute_reply": "2024-03-07T09:57:51.409660Z",
     "shell.execute_reply.started": "2024-03-07T09:57:43.680459Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data for non-defended dataset for OW evaluation\n",
    "import pickle\n",
    "import numpy as np\n",
    "def LoadDataNoDefOW_Evaluation():\n",
    "\n",
    "    print(\"Loading non-defended dataset for open-world scenario for evaluation\")\n",
    "    # Point to the directory storing data\n",
    "    dataset_dir = '/kaggle/input/dataset-non-defended-open-world/'\n",
    "\n",
    "    # X represents a sequence of traffic directions\n",
    "    # y represents a sequence of corresponding label (website's label)\n",
    "    try:\n",
    "        # Load testing data\n",
    "        with open(dataset_dir + 'X_test_Mon_NoDef.pkl', 'rb') as handle:\n",
    "            X_test_Mon = np.array(pickle.load(handle, encoding='latin1'))\n",
    "        with open(dataset_dir + 'y_test_Mon_NoDef.pkl', 'rb') as handle:\n",
    "            y_test_Mon = np.array(pickle.load(handle, encoding='latin1'))\n",
    "        with open(dataset_dir + 'X_test_Unmon_NoDef.pkl', 'rb') as handle:\n",
    "            X_test_Unmon = np.array(pickle.load(handle, encoding='latin1'))\n",
    "        with open(dataset_dir + 'y_test_Unmon_NoDef.pkl', 'rb') as handle:\n",
    "            y_test_Unmon = np.array(pickle.load(handle, encoding='latin1'))\n",
    "\n",
    "        X_test_Mon = np.array(X_test_Mon)\n",
    "        y_test_Mon = np.array(y_test_Mon)\n",
    "        X_test_Unmon = np.array(X_test_Unmon)\n",
    "        y_test_Unmon = np.array(y_test_Unmon)\n",
    "\n",
    "        return X_test_Mon, y_test_Mon, X_test_Unmon, y_test_Unmon\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", str(e))\n",
    "        return None\n",
    "\n",
    "# Call the function to load evaluation data\n",
    "LoadDataNoDefOW_Evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccd6266",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-07T09:57:51.413121Z",
     "iopub.status.busy": "2024-03-07T09:57:51.412788Z",
     "iopub.status.idle": "2024-03-07T10:00:58.449841Z",
     "shell.execute_reply": "2024-03-07T10:00:58.448813Z",
     "shell.execute_reply.started": "2024-03-07T09:57:51.413094Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "def Prediction(trained_model = None, dataset = None):\n",
    "    X_test_Mon = dataset['X_test_Mon'].astype('float32')\n",
    "    X_test_Unmon = dataset['X_test_Unmon'].astype('float32')\n",
    "    print (\"Total testing data \", len(X_test_Mon) + len(X_test_Unmon))\n",
    "    X_test_Mon = X_test_Mon[:, :, np.newaxis]\n",
    "    X_test_Unmon = X_test_Unmon[:, :, np.newaxis]\n",
    "    result_Mon = trained_model.predict(X_test_Mon, verbose=2)\n",
    "    result_Unmon = trained_model.predict(X_test_Unmon, verbose=2)\n",
    "    return result_Mon, result_Unmon\n",
    "def Evaluation(threshold_val = None, monitored_label = None,\n",
    "                   unmonitored_label = None, result_Mon = None,\n",
    "                   result_Unmon = None, log_file = None):\n",
    "    print (\"Testing with threshold = \", threshold_val)\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    # ==============================================================\n",
    "    # Test with Monitored testing instances\n",
    "    # evaluation\n",
    "    for i in range(len(result_Mon)):\n",
    "        sm_vector = result_Mon[i]\n",
    "        predicted_class = np.argmax(sm_vector)\n",
    "        max_prob = max(sm_vector)\n",
    "\n",
    "        if predicted_class in monitored_label: # predicted as Monitored\n",
    "            if max_prob >= threshold_val: # predicted as Monitored and actual site is Monitored\n",
    "                TP = TP + 1\n",
    "            else: # predicted as Unmonitored and actual site is Monitored\n",
    "                FN = FN + 1\n",
    "        elif predicted_class in unmonitored_label: # predicted as Unmonitored and actual site is Monitored\n",
    "            FN = FN + 1\n",
    "\n",
    "    # ==============================================================\n",
    "    # Test with Unmonitored testing instances\n",
    "    # evaluation\n",
    "    for i in range(len(result_Unmon)):\n",
    "        sm_vector = result_Unmon[i]\n",
    "        predicted_class = np.argmax(sm_vector)\n",
    "        max_prob = max(sm_vector)\n",
    "\n",
    "        if predicted_class in monitored_label: # predicted as Monitored\n",
    "            if max_prob >= threshold_val: # predicted as Monitored and actual site is Unmonitored\n",
    "                FP = FP + 1\n",
    "            else: # predicted as Unmonitored and actual site is Unmonitored\n",
    "                TN = TN + 1\n",
    "        elif predicted_class in unmonitored_label: # predicted as Unmonitored and actual site is Unmonitored\n",
    "            TN = TN + 1\n",
    "            \n",
    "    print (\"TP : \", TP)\n",
    "    print (\"FP : \", FP)\n",
    "    print (\"TN : \", TN)\n",
    "    print (\"FN : \", FN)\n",
    "    print (\"Total  : \", TP + FP + TN + FN)\n",
    "    TPR = float(TP) / (TP + FN)\n",
    "    print (\"TPR : \", TPR)\n",
    "    FPR = float(FP) / (FP + TN)\n",
    "    print (\"FPR : \",  FPR)\n",
    "    Precision = float(TP) / (TP + FP)\n",
    "    print (\"Precision : \", Precision)\n",
    "    Recall = float(TP) / (TP + FN)\n",
    "    print (\"Recall : \", Recall)\n",
    "    print (\"\\n\")\n",
    "    log_file.writelines(\"%.6f,%d,%d,%d,%d,%.6f,%.6f,%.6f,%.6f\\n\"%(threshold_val, TP, FP, TN, FN, TPR, FPR, Precision, Recall))\n",
    "\n",
    "# The evaluation of Open World scenario\n",
    "def OW_Evaluation():\n",
    "    evaluation_type = 'OpenWorld_NoDef'\n",
    "    print(\"Evaluation type: \", evaluation_type)\n",
    "\n",
    "    # Create the 'results' directory if it doesn't exist\n",
    "    results_dir = '../results/'\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "    threshold = 1.0 - 1 / np.logspace(0.05, 2, num=15, endpoint=True)\n",
    "    file_name = f'{results_dir}{evaluation_type}.csv'\n",
    "    log_file = open(file_name, \"w\")  # Open the file in text mode, not binary mode\n",
    "    # Load data\n",
    "    dataset = {}\n",
    "    model_name = ''\n",
    "    print (\"Loading data ...\")\n",
    "    #from utility import LoadDataNoDefOW_Evaluation\n",
    "    X_test_Mon, y_test_Mon, X_test_Unmon, y_test_Unmon = LoadDataNoDefOW_Evaluation()\n",
    "    # Load pre-trained model saved from 'Open_World_DF_***_Training.py'\n",
    "    #model_name = '/kaggle/working/DFNet_OpenWorld_NoDef.keras'\n",
    "    model_name = '/kaggle/working/DFNet_OpenWorld_NoDef.keras'\n",
    "\n",
    "\n",
    "    dataset['X_test_Mon'] = X_test_Mon\n",
    "    dataset['y_test_Mon'] = y_test_Mon\n",
    "    dataset['X_test_Unmon'] = X_test_Unmon\n",
    "    dataset['y_test_Unmon'] = y_test_Unmon\n",
    "\n",
    "    print (\"Data loaded!\")\n",
    "    print (\"Loading DF model ...\")\n",
    "    print (\"The log file will be saved at \", file_name)\n",
    "    print (\"-- The log file will contains\")\n",
    "    print (\"-- TP, FP, TN, FN, TPR, FPR, Precision, and Recall for each different threshold\")\n",
    "    print (\"-- These results will be used to plot the ROC or Precision&Recall Graph\")\n",
    "    trained_model = load_model(model_name)\n",
    "    print (\"Model loaded!\")\n",
    "    print (\"Evaluation Type: \", evaluation_type)\n",
    "    print (\"Use the model from \", model_name)\n",
    "    result_Mon, result_Unmon = Prediction(trained_model = trained_model, dataset = dataset)\n",
    "    monitored_label = list(y_test_Mon)\n",
    "    unmonitored_label = list(y_test_Unmon)\n",
    "    log_file.writelines(\"%s,%s,%s,%s,%s,%s  ,%s  ,  %s, %s\\n\" % ('Threshold', 'TP', 'FP', 'TN', 'FN', 'TPR', 'FPR', 'Precision', 'Recall'))\n",
    "    for th in threshold:\n",
    "        Evaluation(threshold_val = th, monitored_label = monitored_label,\n",
    "                   unmonitored_label = unmonitored_label, result_Mon = result_Mon,\n",
    "                   result_Unmon = result_Unmon, log_file = log_file)\n",
    "    log_file.close()  \n",
    "\n",
    "OW_Evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852639f7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3857b5c6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d86c07b7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "practice with other relu #method 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d17404",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ceb9d3d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cabc4f2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fddd8e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4227016,
     "sourceId": 7288812,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-11T02:43:19.425227",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}